<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8 no-js"> <![endif]-->
<!--[if IE 9]> <html lang="en" class="ie9 no-js"> <![endif]-->
<!--[if !IE]><!-->
<html lang="en">
<!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <title>Investigating the Neural Mechanisms of Embodied Intelligence and Brain-Inspired Computing Integrated with the DIKWP Model | WAAC | World Academy for Artificial Consciousness</title>

  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="description" content="International Standardization Committee of Networked DIKWP for Artificial Intelligence Evaluation(DIKWP-SC) World Artificial Consciousness CIC(WAC) World Conference on Artificial Consciousness(WCAC)">
<meta property="og:type" content="website">
<meta property="og:title" content="Investigating the Neural Mechanisms of Embodied Intelligence and Brain-Inspired Computing Integrated with the DIKWP Model">
<meta property="og:url" content="http://www.waac.ac/cooperation/items/EN/01-embodied-intelligence-neural-mechanism.html">
<meta property="og:site_name" content="WAAC | World Academy for Artificial Consciousness">
<meta property="og:description" content="International Standardization Committee of Networked DIKWP for Artificial Intelligence Evaluation(DIKWP-SC) World Artificial Consciousness CIC(WAC) World Conference on Artificial Consciousness(WCAC)">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-06-28T06:00:00.000Z">
<meta property="article:modified_time" content="2025-06-30T10:49:54.660Z">
<meta property="article:author" content="WAAC Editorial">
<meta property="article:tag" content="artificial consciousness, artificial intelligence, academy">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="WAAC | World Academy for Artificial Consciousness" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico">
  
    
  <meta content="{{ title }}" name="description">
  <meta content="{{ title }}" name="keywords">
  <meta content="{{ title }}" name="author">

  <link href="http://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700|PT+Sans+Narrow|Source+Sans+Pro:200,300,400,600,700,900&amp;subset=all" rel="stylesheet" type="text/css">

  <!-- Global styles START -->   
  
<link rel="stylesheet" href="/metronic/assets/plugins/font-awesome/css/font-awesome.min.css">

  
<link rel="stylesheet" href="/metronic/assets/plugins/bootstrap/css/bootstrap.min.css">

  <!-- Global styles END --> 
   
  <!-- Page level plugin styles START -->
  
<link rel="stylesheet" href="/metronic/assets/pages/css/animate.css">

  
<link rel="stylesheet" href="/metronic/assets/plugins/owl.carousel/assets/owl.carousel.css">

  <!-- Page level plugin styles END -->

  <!-- Theme styles START -->
  
<link rel="stylesheet" href="/metronic/assets/pages/css/components.css">

  
<link rel="stylesheet" href="/metronic/assets/pages/css/slider.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/style.css">

  
<link rel="stylesheet" href="/metronic/assets/pages/css/portfolio.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/style-responsive.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/themes/red.css">

  
<link rel="stylesheet" href="/css/theme-styles.css">

  <!-- Theme styles END -->
<meta name="generator" content="Hexo 7.3.0"></head>

<body class="corporate">
  
<!-- BEGIN HEADER -->
<div class="header">
  <div class="container">
    <!--<a class="site-logo" href="/" id="logo">WAAC | World Academy for Artificial Consciousness</a>-->

    <a class="site-logo" href="/">
    <img src="/images/waac_logo.png" style="width: 80%; max-width: 300px; display: block; margin: 0px;" alt="WAAC logo" />
    </a>

    <a href="javascript:void(0);" class="mobi-toggler"><i class="fa fa-bars"></i></a>

    <!-- BEGIN NAVIGATION -->
    <div class="header-navigation pull-right font-transform-inherit">
      <ul>
	
	<li class="">
	  <a  href="/">Home</a>
	</li>
	
	<li class="">
	  <a  href="/events/">Events</a>
	</li>
	
	<li class="">
	  <a  href="/archives/">News</a>
	</li>
	
	<li class="">
	  <a  href="/cooperation/">Call for Collaboration</a>
	</li>
	
	<li class="">
	  <a  href="/about/">About</a>
	</li>
	
	<!-- BEGIN TOP SEARCH -->
	<li class="menu-search">
	  <span class="sep"></span>
	  <i class="fa fa-search search-btn"></i>
	  <div class="search-box">
	    <form action="#">
	      <div class="input-group">
		<input type="text" placeholder="Search" class="form-control st-default-search-input">
		<span class="input-group-btn">
		  <button class="btn btn-primary" type="submit">Search</button>
		</span>
	      </div>
	    </form>
	  </div> 
	</li>
	<!-- END TOP SEARCH -->
      </ul>
    </div>
    <!-- END NAVIGATION -->
  </div>
</div>
<!-- Header END -->

  <div class="container">
  <ul class="breadcrumb">
    <li><a href="/">Home</a></li>
    <li class="active">Investigating the Neural Mechanisms of Embodied Intelligence and Brain-Inspired Computing Integrated with the DIKWP Model</li>
  </ul>
  <div class="main">
    <h1>Investigating the Neural Mechanisms of Embodied Intelligence and Brain-Inspired Computing Integrated with the DIKWP Model</h1>
    <ul>
<li>International Standardization Committee of Networked DIKWP for Artificial Intelligence Evaluation(DIKWP-SC)</li>
<li>World Artificial Consciousness CIC(WAC)</li>
<li>World Conference on Artificial Consciousness(WCAC)</li>
<li>Email: <a href="mailto:&#100;&#117;&#x61;&#x6e;&#121;&#117;&#99;&#111;&#x6e;&#x67;&#x40;&#x68;&#x6f;&#116;&#x6d;&#x61;&#105;&#108;&#46;&#x63;&#111;&#109;">duanyucong@hotmail.com</a></li>
</ul>
<hr>
<h1 id="directory"><a href="#directory" class="headerlink" title="directory"></a><strong>directory</strong></h1><p><a href="#background-and-significance">1. Background and significance </a></p>
<p><a href="#research-objectives-and-overall-technical-roadmap">2. Research objectives and overall technical roadmap</a></p>
<p><a href="#research-content-and-technical-route">3. Research content and technical route</a></p>
<p><a href="#behavior-graph-construction-and-perception-chain-analysis">3.1 Behavior graph construction and perception chain analysis</a></p>
<p><a href="#individual-models-and-spatial-environment-modeling-mechanisms">3.2 Individual models and spatial environment modeling mechanisms</a></p>
<p><a href="#perceptual-motor-coupling-and-world-model-construction">3.3 Perceptual-motor coupling and world model construction</a></p>
<p><a href="#construction-of-brain-inspired-computing-framework">3.4 Construction of brain-inspired computing framework</a></p>
<p><a href="#feasibility-analysis">4. Feasibility analysis </a></p>
<p><a href="#milestones-and-milestones">5. Milestones and milestones </a></p>
<p><a href="#assessment-indicators-and-results-form">6. Assessment indicators and results form</a></p>
<p><a href="#application-promotion-programs">7. Application &amp; Promotion Programs</a></p>
<hr>
<h1 id="1-Background-and-significance"><a href="#1-Background-and-significance" class="headerlink" title="1. Background and significance"></a>1. Background and significance</h1><p>The development of artificial general intelligence (AGI) is gradually moving towards the stage of &quot;embodied intelligence&quot;, that is, giving agents the ability to interact with the body and the environment. A large number of studies have pointed out that <strong>embodied intelligence is the key way to realize human-like intelligence: agents can only truly acquire human-level cognition and adaptability when they are embedded in the physical world and form a closed loop through perceptual feedback and action response. At present, the practice in the fields of robotics and autonomous agents shows that it is difficult for &quot;detached intelligence&quot; that relies only on virtual data training to cope with the complex and changeable real environment, so it is generally believed that embodied intelligence is either the only way to move towards AGI, or should be regarded as part of the definition of AGI.</strong></p>
<p>However, there are still significant challenges to achieving embodied intelligence. First, the <strong>complexity of the sensory-motor integration mechanism makes it difficult for artificial systems to reproduce the efficient sensing-action coordination of living organisms</strong>. Perception and movement are closely coupled in the biological brain, perception will guide movement in real time, and motion feedback will update perception, forming a dynamic closed loop. However, existing artificial intelligence often separates perception, cognition, and behavior, and it is difficult to achieve the integration efficiency of biological systems. Secondly, <strong>spatial understanding and modeling are still difficult: artificial intelligence lacks</strong> [an intrinsic representation similar to the &quot;cognitive map&quot; of the mammalian hippocampus]{.underline}, and it is difficult for AI to automatically construct an understanding of the spatial cognition and physical rules of the environment like living organisms. At present, there are still bottlenecks in the understanding of the physical world of robots, such as poor model generalization, <strong>difficult multimodal fusion, and insufficient real-time performance. For example, it is difficult to align data from different sensors in time and space, the migration of models is hindered due to the difference between the simulated environment and the real environment, and a large amount of data is required to cover environmental changes. These problems severely limit the robustness and versatility of embodied intelligence systems.</strong></p>
<p>In response to the above challenges, this project takes the DIKWP model (Data-Information-Knowledge-Intelligence-Intent) and its artificial consciousness theory as the core support, and explores a new path for the realization of embodied intelligence. The DIKWP model is an artificial consciousness framework originally created by Professor Duan Yucong&#39;s team, which adds the highest layer of &quot;Purpose&quot; on the basis of the classic DIKW (pyramid) model. This expansion integrates subjective intention into the objective cognitive process, forming a five-layer cognitive system from data perception to goal-oriented decision-making, which is regarded as an important theoretical innovation in the field of artificial intelligence. The DIKWP framework comprehensively covers the complete chain from raw data acquisition to intelligent decision-making to action intention, enabling us to systematically incorporate motivation and intention into the agent&#39;s cognitive process. Compared with the traditional architecture that only focuses on perception and reasoning, the DIKWP model highlights &quot;intention-driven&quot; and emphasizes the goals and meanings behind cognitive processes. This makes AI systems not only focus on &quot;how&quot; but also &quot;why&quot; when performing tasks, so as to move towards autonomous intelligence and class consciousness.</p>
<p>The DIKWP model and artificial consciousness theory have shown unique advantages and academic contributions in perceptual construction, self-state cognition, and intention-driven behavior. Firstly, the hierarchical structure of DIKWP corresponds to the human cognitive process from low-level perception to high-level cognition to purpose-oriented action, which can be used to construct the perceptual hierarchy of artificial intelligence step by step. For example, using this model, the data collected by sensors can be refined into meaningful information patterns, which can further form environmental knowledge and intelligent decision-making, and finally the intention layer will guide the direction of behavior. This hierarchical perception construction is expected to solve the current problem of multimodal perception fusion, so that AI can gradually accumulate an understanding of the environment. Secondly, the DIKWP framework introduces elements of metacognition and self-model: its &quot;intelligence&quot; layer contains the ability of reflection and cognitive self-reflection, while the &quot;intention&quot; layer gives the system an internal driving force, which can be regarded as a preliminary expression of self-awareness. Therefore, this model helps AI to recognize its own state, such as understanding the limitations of its own knowledge, and having an overall understanding of its environment and goals, which are the keys to achieving autonomy. Thirdly, the &quot;intention&quot; layer of DIKWP allows the agent&#39;s behavior selection to be guided by internal goals, which has the characteristics of intention-driven behavior. This is of great significance in areas such as reinforcement learning: by explicitly representing &quot;intent&quot; within the agent, it can improve the coherence and purpose of decision-making, and make AI behavior more autonomous and reasonable. Finally, the DIKWP model greatly enhances the interpretability and transparency of AI systems. Because the framework modularizes the internal processing of agents into five layers, developers and evaluators can track each layer of information processing, transforming the previously incomprehensible &quot;black box&quot; decision-making process into a traceable &quot;white box&quot; process. This is particularly important in safety-sensitive fields (e.g., healthcare, autonomous driving), where DIKWP ensures that every step of AI reasoning is evidence-based and reviewable, significantly improving the credibility of decision-making. Based on the above advantages, the DIKWP artificial consciousness model is considered to be an important step towards explainable and high-level intelligence, which provides an innovative way to solve the current &quot;black box&quot; problem of large models and improve the controllability of AI systems.</p>
<p>To sum up, this project is based on the major needs of the country, takes the neural mechanism of embodied intelligence and brain-like computing as the research theme, and introduces the DIKWP artificial consciousness framework in an attempt to break through the bottleneck of traditional agent design. Theoretically, the DIKWP model will provide a unified cognitive architecture for embodied intelligence, so that the system can have both data-driven perceptual learning capabilities and purpose-driven autonomous consciousness characteristics. In terms of application, this theory is expected to solve the current difficulties in biological perception-motion integration and spatial cognitive modeling, and promote the development of robots and autonomous agents in the direction of more intelligent and self-discipline. A large number of patented technological achievements of Professor Duan Yucong&#39;s team (covering cutting-edge directions such as artificial consciousness construction and cognitive operating systems) have been regarded as an important underlying support for safe, controllable and explainable AI in the future. Therefore, integrating the DIKWP model into embodied intelligence research is not only of great scientific significance, but also expected to provide a core technical reserve for China to achieve strategic leadership in the field of AGI.</p>
<h1 id="2-Research-objectives-and-overall-technical-roadmap"><a href="#2-Research-objectives-and-overall-technical-roadmap" class="headerlink" title="2. Research objectives and overall technical roadmap"></a>2. Research objectives and overall technical roadmap</h1><p><strong>Research Objectives: This project aims to construct a set of brain-like intelligence systems that integrate the DIKWP model, so that artificial intelligence can form a prototype of cognition and consciousness through embodied interaction like living beings. Theoretically, the neural mechanisms of embodied intelligence</strong> (including perception-motor coupling, spatial cognition, self-intention, etc.) are revealed and explained by the DIKWP model. In terms of methodology, a brain-inspired computing framework was designed to realize an end-to-end agent model from perception acquisition, knowledge extraction to intention decision-making. In terms of application, an embodied intelligence prototype system was developed to verify the effectiveness of the model in scenarios such as autonomous robots, virtual agents, and cognitive enhancement of large models. The long-term goal of the project is to explore a new path based on the mechanism of biological intelligence, integrating the theory of artificial consciousness, and realizing autonomous, controllable, and explainable brain-like AGI.</p>
<p>Overall technical route: This project will combine the five-layer cognitive structure and artificial consciousness framework of the DIKWP model, and adopt <strong>the route of &quot;biological experimental analysis→ mechanism modeling→ algorithm development →system integration</strong>&quot;, and gradually achieve the research goal. Specifically, it is divided into the following five stages:</p>
<ul>
<li><p><strong>Phase 1: Free Behavior Data Collection. Through the multimodal data collection and behavior recording of free-moving animals, a</strong> large-scale dataset and behavior map covering perceptual input (vision, hearing, posture, etc.) and motor output (behavioral action) are established to provide a basis for subsequent modeling. 【Objective】To obtain a large amount of data with high ecological potency, and to preliminarily describe the law of organism&#39;s perception-action cycle.</p>
</li>
<li><p><strong>Phase 2: Neural Mechanism Modeling. Combined with the results of neuroscience experiments and machine learning methods, the data of Phase 1 were analyzed and modeled, and the key neural mechanisms of biological self-state perception and environmental representation were extracted. For example, the neural activity patterns of animal localization and navigation are analyzed, and the representation methods of spatial cognition are extracted. 【Objective】 To establish a</strong> mesh interaction computing and reasoning model corresponding to the &quot;data-information-knowledge&quot; layer in the DIKWP framework, to reveal the process of how perceptual information is transformed into knowledge representation, and to lay a foundation for higher-level intelligence and intention modeling.</p>
</li>
<li><p><strong>Stage 3: Embodied Representation Learning. Based on the mechanism model of Phase 2, an algorithm that can independently learn the physical rules of the environment and the world model in the interaction is developed. Through the</strong> sensory-motor closed-loop experiment, the artificial intelligence can learn to predict the consequences of actions and form a causal cognition of the environment. 【Objective】 To construct the core model of the &quot;intelligence&quot; layer in the DIKWP framework, to realize the interpretable world model and strategic reasoning ability of the agent to the environment, so that it can produce reasonable decision-making and behavior in the simulated environment.</p>
</li>
<li><p><strong>Phase 4: Brain-inspired computational model construction. Based on the above modules, a complete DIKWP brain-like computing framework was designed</strong>. An efficient perception coding mechanism is introduced to compress the representation of multimodal perception. Realize rapid update modules, so that the model can learn online and continuously adapt. The intention modulation module is added for the goal-oriented regulation of injecting artificial consciousness. 【Objective】Develop a brain-inspired model with data-to-intent full-link processing capabilities, modularly realize the functions of each layer of DIKWP, and run efficiently on a general computing platform or brain-like chip, so as to prepare for system-level applications.</p>
</li>
<li><p><strong>Phase 5: System Application Validation. Integrate the Phase 4 brain-like model into an actual embodied intelligence system (such as an autonomous robot or a bionic agent) to build an application demonstration prototype. Test and verify typical scenarios, including autonomous navigation, interactive operation, target recognition and decision-making in complex environments, etc. 【Objective】 The objective is to verify the performance of the DIKWP embodied intelligence system in real tasks, meet or exceed the index level required by the guidelines, and build an open platform for DIKWP embodied intelligence</strong>, so as to lay the foundation for subsequent promotion.</p>
</li>
</ul>
<p>The above route covers the complete chain from biological data acquisition, mechanism refinement to artificial system implementation, and scenario verification, and each stage is closely connected and progressive: the output (data, model) of the previous stage is used as the interface input to support the next stage of development, and the combination of data-driven and theoretical guidance is realized. Through this strategy of phased implementation in parallel with integrated verification, the achievement of research objectives and the accumulation of results are ensured.</p>
<h1 id="3-Research-content-and-technical-route"><a href="#3-Research-content-and-technical-route" class="headerlink" title="3. Research content and technical route"></a>3. Research content and technical route</h1><p>According to the overall technical route, the research content and key technical solutions of each stage are subdivided as follows:</p>
<h2 id="3-1-Behavior-graph-construction-and-perception-chain-analysis"><a href="#3-1-Behavior-graph-construction-and-perception-chain-analysis" class="headerlink" title="3.1 Behavior graph construction and perception chain analysis"></a>3.1 Behavior graph construction and perception chain analysis</h2><p><strong>Research content: This module corresponds to Phase 1 and aims to obtain and analyze the data basis for biological embodied behavior. On the one hand, we will select animals with typical free behavior paradigms (such as rodents&#39; autonomous exploratory behaviors in open scenes) and use multimodal sensing technology to track their perception-motion processes in a long time</strong>。 The data collected includes: visual images (third-person camera and animal view), auditory signals, position information (GPS&#x2F;positioning system), body kinematics data (accelerometer, gyroscope), and neural activity recordings (neuronal firing or EEG can be recorded simultaneously if possible). Through the method of machine learning, the time synchronization and fusion of multi-source data are carried out to reconstruct the movement trajectory and perception flow of animals in the environment.</p>
<p>On the other hand, this module will introduce the concept of Behavior Atlas to model the graph structure of animal behavior sequences and perceptual inputs. Specifically, the key behavioral states of animals (such as foraging, exploration, obstacle avoidance, etc.) are used as the nodes of the graph, and the association between perceptual stimuli and action response is used as the edge to form an <strong>individual-environment interactive behavior map</strong>。 This kind of map can be seen as a depiction of the &quot;perception-action chain&quot; of animals in a free situation, reflecting a kind of causal chain. For example, when a specific visual signal appears in the environment, the probability that the animal will then take a certain action, etc. Through statistical analysis and pattern mining, we will extract the main perceptual chain (i.e., the sequence pattern from perception to behavior) to reveal the laws that organism perceives to drive behavior in different contexts.</p>
<p><strong>Technical route: Firstly, a multi-modal data acquisition system is built</strong>, including high-definition camera arrays, miniature wearable sensors, etc., to realize synchronous data acquisition of experimental animals without restraint. Secondly, the data preprocessing and annotation pipeline was developed, and computer vision and signal processing technologies were used to denoise, extract features and automatically annotate behavioral events on the original data. For example, deep learning is used to detect animal posture and action categories in videos, and pattern recognition is used to identify relevant segments of neural signals and behaviors. Then, graph construction algorithms (such as time series association rule mining and causal discovery algorithms) are used to construct the processed sequence data into directed graphs or time series networks. Each node represents the information pattern perceived by the environment or the behavior state of the animal, and the edges represent the transition probability or causality from perception to action. Finally, combined with the concept of data layer and information layer of the DIKWP model, the semantic interpretation of the behavior graph is carried out: the original sensing data is regarded as &quot;data&quot;, and the environmental cues and behavioral events extracted from it are upgraded to &quot;information&quot;. Through DIKWP perceptual layer modeling, we can preliminarily verify the laws of agents in low-level <strong>data-information transformation, and lay a foundation for subsequent knowledge layer modeling.</strong></p>
<p><strong>Expected Results: This module will produce a free-behavior multimodal dataset and a corresponding behavior graph model</strong>. The size of the dataset is expected to be more than 10 hours of behavioral recording, including a wealth of perceptual-motor examples. The behavior map will quantitatively display the typical behavioral chains of animals, such as sequences such as &quot;hearing a sound→ turning the head to position→ moving closer&quot; and their probabilities. By analyzing the structure of the atlas, we expect to find several important rules, such as the time delay distribution of perceptual stimuli and motor responses, and <strong>the synergistic effect of multimodal stimuli on behavior choice. This study not only provides guidance for the modeling of biological neural mechanisms, but also verifies the applicability of the perception layer in the DIKWP model to</strong> the modeling of individual-environment interactions.</p>
<h2 id="3-2-Individual-models-and-spatial-environment-modeling-mechanisms"><a href="#3-2-Individual-models-and-spatial-environment-modeling-mechanisms" class="headerlink" title="3.2 Individual models and spatial environment modeling mechanisms"></a>3.2 Individual models and spatial environment modeling mechanisms</h2><p><strong>Research content: This module corresponds to Phase 2, focusing on the neural mechanism of animal self-state perception and spatial environment modeling, and using the DIKWP framework to explain it hierarchically. With the help of behavioral data and existing neuroscience knowledge, we will build two levels of models: one is the individual layer model</strong>, which describes the mechanism of perception and representation of animals in their own state (such as position, orientation, and movement intention); The second is the environmental layer model, which describes the perception representation and internal modeling process of the animal on the external space (including the terrain layout, the location of the target, etc.).</p>
<p>In terms of individual models, we focus on the ability of animals to locate themselves in the environment (i.e., ontological localization) and internal state cognitive mechanisms. For example, the vestibular system, proprioception, and motor copy signals in the mammalian brain work together to make animals aware of their position in space and the speed at which they move. There are also positional cells and grid cells in the hippocampus-entorhinal cortex system, which are thought to encode the current position and grid-like spatial coordinates, respectively, thus providing an intrinsic localization framework. We will try to reconstruct an autonomous position-aware model using the position trajectory data obtained in Phase 1 and the reports on relevant neural activity in the literature: the input can be a simulated vestibular acceleration signal and visual stream, and the model outputs the estimated self-coordinates and orientation through integration and pattern recognition. This process corresponds to the &quot;data→ information→ knowledge&quot; of DIKWP: the original sensory data is processed to extract meaningful information about one&#39;s own motion (e.g., speed, steering events), and then integrated into a knowledge representation of one&#39;s own state (e.g., inferring &quot;I am currently in a certain position in space&quot;).</p>
<p>In terms of environmental models, we study the neural mechanisms by which animals construct environmental cognitive maps. Organisms are able to gradually build internal models of their environment through exploration, such as remembering the distance and direction relationship of the places they encounter, the location of obstacles, the location of important targets, etc. Neuroscience studies have shown that the hippocampus not only localizes itself, but also encodes the topological relationships of the environment. The cerebral cortex vision and parietal lobe region abstract objects and topographical features in space. To model this capability, we will adopt a hierarchical spatial representation learning approach: the lower layer uses a deep neural network to extract environmental features from vision&#x2F;radar data (corresponding to the information layer of DIKWP); In the middle layer, the graph structure or grid representation is used to integrate the location relationships obtained from multiple explorations to form an environmental topology map or cognitive map (corresponding to the knowledge layer). The high-level combination of reinforcement learning or planning algorithms enables the model to perform path inference and target search based on internal maps (corresponding to the intelligence layer). We will refer to the idea of SLAM (Simultaneous Localization and Mapping) algorithm, but add bio-inspired components, such as the brain-like hippocampus network for efficient map updates, and grid cell coding for the generation of continuous spatial coordinates.</p>
<p><strong>Technical route: Firstly, by analyzing the spatial trajectory of the behavioral data in Phase 1, representative environmental scenarios</strong> (such as mazes and open fields) were selected for simulation and modeling. Then, a simulated environment was set up to repeat the animal&#39;s exploration process, and virtual sensing data and motion decisions were recorded. Then, for the individual model, a localization algorithm that fuses multi-source sensations is designed, such as Kalman filter fusion accelerometer and visual odometry, to achieve continuous estimation of one&#39;s own position. Or use a recurrent neural network to memorize a sequence of movements to predict the current position. For the environment model, a cognitive map learning algorithm was developed: topology maps (nodes represent places in the environment, edges represent reachability) and metric maps (continuous coordinate systems represent spaces) were used. We will explain this process by introducing the concept of information layer and knowledge layer in DIKWP <strong>– the information layer extracts useful information from the perception of the environment</strong> (e.g., the location of landmarks, obstacles), and the knowledge layer forms rules and models about the environment (e.g., &quot;room layout maps&quot; or &quot;navigation networks&quot;). Finally, by comparing the output of the model with the behavior of real animals, we test our hypotheses about neural mechanisms, such as whether the model reproduces the path integration ability of organisms, and whether it can maintain localization when occluded or some clues are missing like animals.</p>
<p><strong>Expected Results: This module will produce an embodied intelligent individual-environment cognitive model</strong> capable of exhibiting animal-like localization and navigation capabilities in a simulated environment. The specific achievements include: (1) <strong>Individual state perception module</strong>: realizes the self-position&#x2F;posture estimation of the self-agent based on multi-sensory input, and its accuracy is close to that of the high-configuration sensor fusion algorithm, but the structure is closer to the biological mechanism. (2) <strong>Environmental Cognitive Map Module</strong>: It can learn the topology of the environment by exploring, and finally represent the environment in the form of a map or map to support subsequent path planning. (3) At the theoretical level, the hierarchical structure of DIKWP is used to explain the modeling process of spatial perception, and the progressive relationship of &quot;information-knowledge-wisdom&quot; in spatial understanding is clarified. This part of the results will provide the core algorithm for the subsequent construction of the world model, and also provide a new brain-like idea for the future robot navigation system.</p>
<h2 id="3-3-Perceptual-motor-coupling-and-world-model-construction"><a href="#3-3-Perceptual-motor-coupling-and-world-model-construction" class="headerlink" title="3.3 Perceptual-motor coupling and world model construction"></a>3.3 Perceptual-motor coupling and world model construction</h2><p><strong>Research content: This module corresponds to Phase 3, and the core is to realize the cyclic mechanism of perception-motion coupling on the bionic model, so that the agent can learn the world model through continuous interaction</strong>。 The so-called world model refers to the internal representation and simulation device of the external physical environment and its dynamic laws within the agent. The biological brain is thought to have an internal &quot;simulator&quot; capable of predicting the outcome of an action and adjusting behavioral strategies accordingly. This ability stems from the causal learning implicit in a lot of trial and error between perception and movement, such as the infant learning the rules of physics by constantly trying to manipulate objects. Our goal is for AI to interact with each other to gradually gain interpretable rule cognition of the environment, form a world model that can be internalized and deduced, and use the model to make intent-driven decisions.</p>
<p><strong>Technical route: We will adopt the &quot;Perception-Action Loop&quot; training paradigm</strong>. In the aforementioned simulation environment, the agent is allowed to make decisions based on its own perception, and then obtains feedback perception from the environment, and so on. In order for the agent to learn the environmental rules efficiently, it is necessary to implant reasonable structures and training objectives in the model: (1) <strong>Prediction model</strong>: Design a model that accepts the current state representation and candidate actions, and outputs the predicted next state or perception result. This can be achieved with neural networks, the training goal of which is to minimize errors with real-world feedback. Through continuous training, the model will capture the causal patterns of the environment (e.g., object dynamics, collision effects, etc.). (2) <strong>Explanatory rule extraction</strong>: In order to ensure that the physical rules of the model are explainable, we consider introducing symbolic learning or causal discovery methods to extract human-understandable rules from the prediction model. For example, by approximating the decision boundaries of a neural network through a decision tree or logistic regression, a rule in the form of an &quot;If-Then&quot; is extracted (e.g., &quot;If not supported, the object falls&quot;). (3) <strong>Reinforcement learning and intent guidance</strong>: At the same time, reinforcement learning is used to train the policy network of the agent, so that it can use the predictive model to make planning decisions, not just reflexive responses. The intelligence <strong>layer is equivalent to the agent&#39;s ability to use the world model to reason about and evaluate multiple action plans, and the intention layer provides guidelines for strategy selection, that is, to achieve the goal oriented to choose behavior. For example, we define the intrinsic goal of the agent (from the intent layer, such as navigating to a specific place, keeping itself safe, etc.), and let the reinforcement learning algorithm select the optimal action that satisfies the intent while considering the output of the prediction model.</strong></p>
<p>In this process, we also investigate how perceptual-motor <strong>coupling can improve the generalization ability of the model. One hypothesis is that by unifying perceptions and representations of actions in cognitive processes</strong>, models can better understand &quot;physical cause and effect&quot; and thus rely less on specific senses to generalize from one type of environment to a new one. Therefore, we will try to have the middle representation of the world model accept both perceptual and motor inputs to learn a latent variable representation that fuses space-dynamic. This representation seeks to correspond to certain physical quantities in reality (e.g., momentum, force) to enhance the robustness of the model to environmental changes.</p>
<p><strong>Expected Outcomes: Through this module, it is expected to obtain: (1) a self-evolving world model: the</strong> agent can establish an internal simulation of environmental dynamics through its own exploration in the simulated environment, and its prediction accuracy reaches a certain standard (for example, the error in predicting the next state in a complex environment is lower than the threshold required by the guidelines). More importantly, we will extract a number of explicit physical rules to verify that the agent has indeed learned the laws of the environment, such as the conservation of collisions, the influence of gravity, etc., and express them in an interpretable form. (2) An intention-driven decision-making system: on the basis of the world model, the agent can make inferential decision-making according to the target intention. The metrics include: when given a new task goal, the agent can simulate a series of action plans through the internal model, and select the optimal plan to execute, and the success rate and efficiency are significantly better than those of the strategy without the world model. (3) Theoretically, it proves the value of the intelligence layer + intention layer in the DIKWP model to the agent&#39;s behavior choice: that is, the system with internal simulation and goal guidance has significantly improved its adaptability and decision-making rationality in unknown scenarios. This will become a key support for the construction of brain-like autonomics.</p>
<h2 id="3-4-Construction-of-brain-inspired-computing-framework"><a href="#3-4-Construction-of-brain-inspired-computing-framework" class="headerlink" title="3.4 Construction of brain-inspired computing framework"></a>3.4 Construction of brain-inspired computing framework</h2><p><strong>Research content: This module corresponds to Phase 4 and aims to integrate and develop an in-person intelligent brain-like computing framework based on the above mechanisms and models</strong>. Guided by the DIKWP model, this framework realizes the organic combination of functional modules at each layer, and focuses on achieving efficient, real-time, and adaptive engineering. We focus on three key technologies: <strong>[compressive sensing encoding]{.underline}</strong>, <strong>rapid update learning, and intent control mechanisms</strong> to comprehensively improve system performance.</p>
<p><strong>Compressive sensing encoding mechanism: The perceptual system of the biological brain has amazing data compression and extraction capabilities, such as the human eye distilling huge visual data into sparse key features and transmitting them to the brain. Inspired by this, we will design an efficient perceptual coding module in the framework. This can be done by employing event-driven perception or attention mechanisms</strong> that focus only on changes or perceptual information relevant to the task at hand to reduce ineffective data transmission; Sparse representation and compressed sensing algorithms are used to greatly reduce the data dimension under the premise of ensuring that key information is not lost. For example, based on the information layer semantics of DIKWP, the original sensor data can be symbolized or represented by a feature map, so that the subsequent layer can directly process the high-level semantics instead of the massive raw data. The compressive sensing module will be embedded in the lower layer of the framework to realize edge-side preprocessing, ensure that the overall data throughput of the system is within the real-time range, and improve the efficiency of perception coding (the compression ratio and information retention rate are intended to be used as indicators).</p>
<p><strong>Rapid update of learning modules: Embodied intelligence faces a dynamic and ever-changing environment, which requires the model to have continuous learning and online update capabilities. We will introduce brain-like synaptic plasticity and memory unit design into the framework, so that the system can quickly adapt to new knowledge and new situations. For example, drawing on the brain</strong>&#39;s hippocampus-neocortex memory system, we can construct dual pathways for learning: one fast pathway for immediate memory (short-term memory, such as working memory modules) and the other for consolidating knowledge (long-term memory, such as through offline batch updates). In terms of algorithms, <strong>meta-learning or small-shot learning techniques can be used to allow the model to adjust internal parameters after a small amount of new data or a few interactions. We will also implement a modular update mechanism: when environmental changes are localized, only the parameters of the relevant modules are updated, and the rest of the modules remain stable, thus speeding up convergence. For example, if a change in ambient lighting primarily affects the Visual Perception module, you only need to update the model of the Perception Coding submodule. Through these means,</strong> each layer in the DIKWP framework will have a certain degree of autonomous evolution ability, especially the knowledge layer and the intelligence layer can refresh their cognition in real time with changes in the environment. We will evaluate the effect of rapid updates with metrics such as adaptation time constant, <strong>transfer learning performance, etc.</strong></p>
<p><strong>[Intention regulation module]{.underline}: This is one of the core innovations of the DIKWP framework that distinguishes it from the traditional architecture, aiming to simulate the unified regulation of various cognitive modules in the frontal lobe. We will develop a centralized intent management unit</strong> that stores and maintains the high-level state of the current system, such as goals, motivations, etc. On the one hand, the module applies guidance signals downwards to each level: for example, adjusting the attention focus of the perception module according to the current intention (similar to selective attention), adjusting the priority of knowledge retrieval, and influencing the preference function of the decision evaluation of the intelligence layer; On the other hand, it also upstreams feedback from modules for self-monitoring and intent updates. In terms of technical implementation, we may use reinforcement learning agents or logical rules to implement the unit of intent. For example, when the system detects that the current strategy deviates from the target, the intent module can send a signal to prompt the intelligent layer to re-plan the path. Or when long-term goals change, trigger a refactoring of the knowledge base to accommodate the new goals. The intent control module will also be responsible for interfacing with human users or high-level instructions to ensure that the system behavior is always under moral and safety constraints (which also corresponds to the regulation of AI behavior ethics by artificial consciousness).</p>
<p><strong>Framework integration and brain-like implementation: After implementing each submodule, we will do framework-level integration. The distributed parallel computing architecture is used to simulate the parallel information processing of multiple regions of the brain, and the communication delay between each module is minimized. At the same time, we should pay attention to the adaptation of brain-like chips</strong>: select appropriate heterogeneous computing hardware (such as GPU acceleration, FPGA, neuromorphic chips, etc.) to deploy key algorithm modules to improve the energy efficiency ratio. For example, perceptual coding and partial neural network inference can be ported to a dedicated acceleration chip, and complex decisions and stored are executed on the CPU or in the cloud. Through the collaborative optimization of software and hardware, the whole system can reduce power consumption while meeting real-time performance, and have the ability to operate autonomously for a long time.</p>
<p>**Expected Results: This module will eventually produce a complete implementation of the DIKWP embodied intelligent brain-like computing framework, including software architecture and hardware deployment scheme. The specific landmark achievements are: (**1) <strong>Modular prototype system</strong>: realize the integrated operation of the five-layer modules of data, information, knowledge, wisdom and intent, the internal interface and information flow are clear, and the functions of each module are verified by unit tests. (2) <strong>Key technical indicators meet the standards</strong>: such as the perceptual data compression ratio reaches the expected goal (improving the efficiency by several times), the model update is completed in seconds, and the decision-making frequency meets the real-time requirements (for example, the ≥Hz level). (3) <strong>Brain-like characteristics are verified in the experimental environment</strong>: the system shows a certain degree of fault tolerance and robustness, and the whole can still degrade and operate when the local module fails (similar to the functional compensation after brain injury); Good interpretive skills and goal-driven behaviors in test tasks. For example, for a complete decision-making process, we are able to trace the results of each layer of processing and have the system explain &quot;why the behavior was taken&quot; to prove that its artificial awareness module works. The framework will serve as the foundation for the next phase of system adoption, preparing the ground for building a usable embodied intelligence platform.</p>
<h1 id="4-Feasibility-analysis"><a href="#4-Feasibility-analysis" class="headerlink" title="4. Feasibility analysis"></a>4. Feasibility analysis</h1><p><strong>Research basis: This project relies on the profound accumulation of artificial consciousness, neural computing and brain-like systems by Professor Duan Yucong and his team. Professor Duan Yucong&#39;s team took the lead in proposing the DIKWP artificial consciousness model and has achieved a series of achievements in this field. In terms of theoretical research, the team started the research on the expansion of the DIKW system as early as the 2010s, developed the methods of knowledge graph and cognitive semantics, and relied on the &quot;&quot; in 2020</strong>The research on &quot;Graph Expansion and Modeling of DIKW Knowledge System&quot; won the third prize of Wu Wenjun Science and Technology Award, the highest award of Chinese artificial intelligence. Since then, the team has continued to deepen the DIKWP theory, published a number of high-level papers in the fields of knowledge representation, semantic computing, artificial consciousness evaluation, etc., and applied for a large number of related invention patents. According to reports, as of the beginning of 2025, Professor Duan Yucong, as the first inventor, has been authorized 114 invention patents (including 15 PCT international patents), covering a wide range of fields such as large model training, artificial consciousness construction, cognitive operating system, and AI governance. These achievements are regarded as an important foundation for future explainable and secure AI, and provide solid technical support for the move towards AGI.</p>
<p>Talent and team: The team has a multidisciplinary research team, with core members including experts in artificial intelligence, computational neuroscience, robotics, cognitive psychology and other fields. Professor Duan Yucong is currently a Corresponding Member of the National Academy of Artificial Intelligence of the United States, a Foreign Academician of the National Academy of Sciences of Serbia, an Academician of the International Academy of Advanced Technology and Engineering, and the Chairman of the World Association of Artificial Consciousness. There are not only senior researchers in the team who are responsible for algorithm and theoretical research, but also engineers and technicians who are responsible for system development, so as to realize the equal emphasis on scientific research and engineering implementation. This cross-disciplinary talent structure ensures that all aspects of the project, from neural mechanism research to software and hardware implementation, are professionally supported.</p>
<p><strong>Research conditions: The team has built a special DIKWP artificial awareness laboratory</strong>, equipped with advanced software and hardware resources. In terms of hardware, the laboratory has GPU clusters and high-performance computing servers for large-scale model training and brain-like simulation operations. Equipped with a variety of robots and sensing equipment, it can carry out embodied intelligent physical experiments; It is also planned to introduce domestic advanced brain-like chip breadboards for new architecture verification. In terms of software, the team has developed tools such as the DIKWP white-box assessment framework to test the cognitive processes of AI in a layered manner. In addition, the team has established cooperative relations with well-known domestic scientific research institutions (such as the Institute of Neuroscience, the Key Laboratory of Robotics, etc.), and can receive assistance in the development of biological experiment data and biomimetic algorithms. A good foundation for multidisciplinary cooperation will ensure the smooth implementation of the project.</p>
<p>Risk control: This project is challenging, but the team&#39;s existing research base reduces the main technical risks. For example, the theoretical perfection and early verification of the DIKWP model will reduce the possibility of detours in the framework design. The data noise and uncertainty that may be encountered in free behavior data collection can be controlled by the white-box evaluation and data cleaning technology in the team&#39;s patent. Each sub-project has corresponding pre-research results or technical reserves, and once technical difficulties arise, the team also has the ability to quickly adjust the plan through domestic and foreign cooperation and its own experience. As a result, the project is highly viable.</p>
<h1 id="5-Milestones-and-milestones"><a href="#5-Milestones-and-milestones" class="headerlink" title="5. Milestones and milestones"></a>5. Milestones and milestones</h1><p>The project is planned to have a five-year cycle, and the phased goals and milestones are as follows:</p>
<ul>
<li><p><strong>Year 1 (2025):</strong> Completion of the construction and preliminary analysis of the free behavior multimodal dataset. Successfully obtain data on at least 100 hours of animal freedom; Establish a behavior graph model and publish 1 open dataset paper. Milestone: Obtain a behavioral map covering the main perceptual-motor patterns to provide a quantitative basis for subsequent modeling.</p>
</li>
<li><p><strong>Year 2 (2026):</strong> Complete the development of a cognitive model of individuals and the environment. Build a simulation experiment environment to reproduce the experimental scene of the first year; One set of autonomous subject localization and one set of environment map construction algorithms are realized, and its performance reaches more than 80% efficiency of the classical SLAM method. He has published 1~2 papers on neural mechanism models. Milestone: The key algorithm of the information layer&#x2F;knowledge layer in the DIKWP framework was developed, and the model was verified to simulate the cognitive function of biospace.</p>
</li>
<li><p><strong>Year 3 (2027):</strong> Complete integration of the world model with the decision-making system. The trained agent forms a model of the physical world in the simulated environment, and the prediction accuracy reaches more than 90%. With the integrated intent-driven decision-making module, the agent has a 20% success rate of the baseline model in the two new tasks. He has published 1 paper related to reinforcement learning and world model, and applied for 1 invention patent. Milestone: The functions of the intelligence layer and the intent layer in the DIKWP framework have been realized, and the prototype of the agent with self-deduction and goal-oriented behavior has appeared.</p>
</li>
<li><p><strong>Year 4 (2028):</strong> Complete the development and optimization of the brain-inspired computing framework. Deploy the prototype of the DIKWP brain-like system in the laboratory environment to realize the collaborative operation of the software and hardware of each module; The real-time performance of the system meets the standard (decision delay &lt; 100ms), and the perceptual data compression rate is increased by more than 5 times. Improve the rapid learning and intention control mechanism, and the system can re-adapt within 1 minute after the environment changes. Apply for 2 soft works or invention patents. Milestone: Launched a prototype of a brain-inspired intelligence system with practical value, demonstrating stable, adaptive and explainable intelligent behavior in a controlled environment.</p>
</li>
<li><p><strong>Year 5 (2029):</strong> Completion of application verification and construction of an open platform. Migrate the system to an embodied intelligent platform (such as a service robot) in real scenarios, complete at least two application scenario tests (such as autonomous navigation and human-computer interaction tasks), and achieve predetermined performance indicators (such as navigation and positioning error of &lt;0.5m, and the success rate of interactive command response is &gt;95%). Build an online open platform, and release the DIKWP embodied intelligence development toolkit and typical application demonstrations for scientific research and industry to try. More than 2 high-level papers have been formed, and 1 technical standard or guideline has been condensed. Milestone: The DIKWP embodied intelligent system has passed the real-world assessment, the maturity of the core technology has been improved, and it has begun to be widely promoted.</p>
</li>
</ul>
<p>These milestones quantify outcome indicators to ensure that there is a clear basis for evaluation each year. These phased results will be gradually accumulated to achieve the overall goal of the project.</p>
<h1 id="6-Assessment-indicators-and-results-form"><a href="#6-Assessment-indicators-and-results-form" class="headerlink" title="6. Assessment indicators and results form"></a>6. Assessment indicators and results form</h1><p>In order to objectively evaluate the effectiveness of the project, we have formulated an assessment system at two levels: technical indicators and achievement forms:</p>
<p><strong>Technical assessment indicators:</strong></p>
<ul>
<li><p>Perceptual encoding efficiency: measures the ability of the perceptual layer to compress and extract raw data. For example, based on the proportion of compressed data in the original data and the information retention rate, the goal is to compress the amount of data to less than 20% of the original amount while ensuring 95% of the valid information. This indicator reflects the efficiency of the system in processing multimodal perception information in real time.</p>
</li>
<li><p>Prediction accuracy and real-time: It measures the accuracy of the prediction of the environmental state and the timeliness of decision-making by the intelligent layer world model. Specifically, in the standard physical test, the prediction error of the model for the next time state MSE is lower than the specified threshold; In a dynamic decision-making task, the calculation delay of each decision does not exceed a millisecond-level upper limit. This metric ensures that the system has a high-quality environmental model and rapid response capabilities.</p>
</li>
<li><p>Modeling versatility: Evaluate the ability of the system to adapt to new environments and tasks. The performance degradation and recovery time of the model in the changing scenario are quantified. For example, the navigation success rate decreases by no more than 30% at the initial stage after changing the environment, and returns to more than 90% of the original performance after learning adjustment. The convergence speed of new task training is X times higher than that of traditional models. This indicator reflects the universality and portability of the DIKWP framework in different applications.</p>
</li>
<li><p><strong>DIKWP module function implementation and verification: Confirm that all five layers of modules in the system are implemented, and verify their independent functions and cooperation effects through testing. This includes: the data&#x2F;information layer can correctly extract the key features of the environment, the knowledge layer can store inference rules, the intelligence layer can make reasonable decisions in complex situations, and the intention layer can effectively guide behavior choices. We will use the team&#39;s existing DIKWP white-box assessment system</strong> to conduct a qualitative and quantitative assessment of each layer exposed by the white-box. Metrics in the form of indicators such as the accuracy of the output of each layer, the sensitivity of the system to intervention (such as manually modifying the output of a certain layer), etc., to verify the effective closure of the entire DIKWP chain.</p>
</li>
<li><p>Artificial Consciousness and Explanatory Power: Evaluate the interpretability of the system&#39;s decision-making process and whether it reflects the characteristics of artificial consciousness. This is done by checking whether the system can output human-understandable decision-making basis in real-time prediction and behavior selection. For example, for each action decision, the system is able to give an explanation (expressed in natural language or logical rules) based on its knowledge and intent, and correspond to the actual effect. We will introduce the &quot;<strong>Consciousness Level Test</strong>&quot;, which refers to the white-box cognitive assessment indicators proposed by the team to evaluate whether the system&#39;s ability in perception, knowledge, wisdom, and intention is sound. The goal is to achieve a predetermined level of awareness assessment score at the end of the project, proving that it has significantly improved its autonomy and purpose.</p>
</li>
</ul>
<p><strong>Form of Output:</strong> The project is expected to produce a wealth of research results and practical products, including but not limited to:</p>
<ul>
<li><p>Publications: He has published no less than 5 papers in top journals such as artificial intelligence and neuroscience, systematically expounding the theoretical methods and experimental results of the DIKWP embodied intelligence model. At the same time, write monographs or research reports, condense the academic ideas of the project, and form a technical white paper for external release.</p>
</li>
<li><p>Intellectual property rights: The new algorithms and new devices generated in the research process will actively apply for domestic and foreign invention patents, and it is expected that no less than 3 authorized patents will be issued to consolidate the independent intellectual property rights of technological innovation achievements.</p>
</li>
<li><p><strong>Software and hardware systems: Deliver the DIKWP Embodied Intelligence Open Platform</strong> (see the next section for details) as an important outcome form of the project. The platform includes a suite of software toolkits, such as a source code repository for the Brain-like Cognitive Framework, a dataset and model library, a white-box evaluation tool, and a demonstration application programming interface (API). In terms of hardware, we have completed the prototype of a brain-inspired computing system (a robot or embedded device that can run in a laboratory environment) and provided a simulation interface on an open platform for users to try.</p>
</li>
<li><p><strong>Standards and specifications: Participate in the formulation of technical standards or guidelines in related fields based on project experience. For example, we will promote</strong> the research and formulation of artificial awareness assessment standards and <strong>embodied intelligence interface specifications, so as to feed back the industrial supervision and academic community with the results.</strong></p>
</li>
<li><p>Talent training: Through the implementation of the project, a group of interdisciplinary talents will be cultivated, including postdoctoral fellows, doctoral students and engineers. It is expected to train no less than 10 talents to further expand the research team of brain-like intelligence and artificial consciousness in China.</p>
</li>
</ul>
<h1 id="7-Application-Promotion-Programs"><a href="#7-Application-Promotion-Programs" class="headerlink" title="7. Application &amp; Promotion Programs"></a>7. Application &amp; Promotion Programs</h1><p>The research results of this project will be oriented to multiple application fields to promote the implementation and expansion of embodied intelligence technology:</p>
<p><strong>(1) Embodied intelligent robots: The DIKWP brain-like model of this project is applied in the fields of service robots and industrial robots to significantly improve its autonomy and adaptability. For example, the system is deployed on the home service robot to enable it to grasp the layout of the home environment and the owner&#39;s preference through continuous learning, so as to achieve more flexible housekeeping assistance; The application of industrial mobile robots allows them to autonomously plan paths, avoid emerging obstacles, and optimize handling efficiency in dynamic production floors. Due to the modular transparency of the DIKWP architecture, the cause of the robot&#39;s decision-making error can be traced and corrected in time, improving reliability and safety. This will yield direct benefits in robotics scenarios that require a high degree of autonomy, such as smart manufacturing, medical care, and emergency rescue. The project team will work with robot manufacturers to build pilot demonstrations and promote technology transfer.</strong></p>
<p><strong>(2) Autonomous agents and unmanned systems: The results of this project are also applicable to autonomous systems such as unmanned vehicles and drones, as well as intelligent game agents. By fusing the DIKWP model, these agents will gain stronger environmental understanding and decision-making capabilities. For example, driverless cars can use this framework to achieve hierarchical cognition of the traffic environment, from raw sensor data to traffic knowledge, to driving intention decision-making, to improve the reliability of perception and decision-making interpretation, and meet the requirements of autonomous driving for safety and controllability. UAV swarms can use the intent layer for task assignment and cooperative flight to ensure that the overall mission goal is achieved. In video games and virtual environments, the introduction of embodied intelligent agents can create more realistic AI behaviors, give &quot;awareness&quot; and &quot;purpose&quot; to game characters, and enhance the interactive experience and training value. The team plans to test the multi-agent collaboration task on the simulation platform to verify the potential of the framework in multi-agent systems.</strong></p>
<p><strong>(3) Expansion of cognitive ability of large models: The DIKWP artificial awareness framework can also be used to improve the cognitive ability and interpretability of current large-scale pre-trained models (such as large language models and visual-language models). In the absence of environmental interaction and autonomy, the current large model has the &quot;black box&quot; problem of understanding limitations and unexplainable decision-making. Our solution is to integrate the cognitive chain of DIKWP around the large model: through the &quot;model servitization&quot; method, the output of the large model is used as the data&#x2F;information input of the DIKWP framework, and then processed by the knowledge and intelligence layer, and the results are screened and adjusted by the intent layer. This is equivalent to equipping the large model with a &quot;thinking brain&quot; to reflect, verify, and guide the purpose of the answers it gives. For example, in the Q&amp;A system, after the large language model generates a preliminary answer, the DIKWP intelligence layer can verify the correctness of the answer according to the knowledge base, and the intent layer adjusts the answer style or depth according to the user&#39;s intent, and finally outputs a more accurate response that meets the user&#39;s needs. In addition, we can use the &quot;knowledge quotient&quot; (artificial awareness level) white-box assessment system developed by the team to evaluate the large model, find out its shortcomings in knowledge, wisdom, and intention, and then make up for it through the DIKWP model. Such AI system integration is expected to make existing AI &quot;smarter and more reliable&quot; and play a greater role in applications such as intelligent customer service and decision-making assistance.</strong></p>
<p><strong>(4) Model servitization and platform openness: In order to promote industry-university-research applications, this project will provide model services and development interfaces on the DIKWP embodied intelligence open platform. On the one hand, various functional modules, such as the perceptual coding service, the world model inference service, and the intent decision service, are deployed through the microservice architecture for different applications to call on demand. This model as a service makes it easy for developers to integrate our brain-inspired intelligence functions into their respective products, without having to build an embodied intelligence system from scratch. On the other hand, the open platform will provide standardized data interfaces and evaluation benchmarks to</strong> reduce the cost of external team access. The platform also plans to open up part of the source code and demonstration applications, encourage secondary development and module replacement, and make it a shared testing ground in the field of embodied intelligence. By holding developer competitions and workshops, we will gradually expand the influence of the DIKWP open platform, attract universities and enterprises to participate, form an ecological cycle, and accelerate technological evolution.</p>
<p><strong>(5) Adaptation and industrial transformation of brain-inspired chips: This project forward-looking layout of new hardware such as brain-inspired chips to ensure the long-term competitiveness of the results. In the later stage of the research, we will cooperate with relevant domestic enterprises to try to transplant the DIKWP framework to dedicated brain-inspired computing hardware, such as spiking-like neural network chips, heterogeneous fusion chips, etc. This will verify the performance of our algorithm on low-power, high-parallel hardware, and tailor the algorithm to take advantage of the advantages of the chip (e.g., using spiking neural networks to implement event-driven intents for the block). Once the verification is successful, we will actively promote cooperation with chip manufacturers and machine enterprises to promote the integration of software and hardware solutions, and realize applications in robot controllers, unmanned system navigation equipment and other products. These transformation efforts are expected to be carried out through horizontal projects or achievement incubation, and will continue to be carried out after the completion of the project, and finally realize the industrial implementation of the technology.</strong></p>
<p>In summary, while completing the scientific research task, this project will promote the application of the results through multiple channels, from academic impact to industrial value. By building an open platform and ecosystem, we are confident that the DIKWP model will become an important basic framework in the field of embodied intelligence and artificial consciousness, and will be adopted by a wider range of researchers and engineers, so as to continuously iterate and improve, and help China take the initiative in the future intelligent technology competition.</p>
<hr>
 
  </div>
</div>

    <!-- BEGIN PRE-FOOTER -->
    <div class="pre-footer">
      <div class="container">
        <div class="row">
          <!-- BEGIN BOTTOM ABOUT BLOCK -->
          <div class="col-md-4 col-sm-6 pre-footer-col">
            <h2>About Us</h2>
            <p>World Academy for Artificial Consciousness(WAAC)</p>
          </div>
          <!-- END BOTTOM ABOUT BLOCK -->

          <!-- BEGIN BOTTOM CONTACTS -->
          <div class="col-md-4 col-sm-6 pre-footer-col">
            <h2>Contact</h2>
            <address class="margin-bottom-40">
              Paris, France<br>
              <!-- <br>
              <br> -->
              <!-- Phone: <br> -->
              Email: <a href="mailto: contact@waac.ac"> contact@waac.ac</a><br>
            </address>
          </div> 
          <!-- END BOTTOM CONTACTS -->

	
          <!-- BEGIN TWITTER BLOCK --> 
          <div class="col-md-4 col-sm-6 pre-footer-col">

	  <!-- <a data-tweet-limit="1" class="twitter-timeline" data-theme="dark"
	  target="_blank" rel="noopener" href="https://twitter.com/computerlab_">Tweets by @computerlab_</a> -->

	  <script>!function(d,s,id){var
	  js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

          </div>
          <!-- END TWITTER BLOCK -->
	
        </div>
      </div>
    </div>
    <!-- END PRE-FOOTER -->

    <!-- BEGIN FOOTER -->
    <div class="footer">
      <div class="container">
        <div class="row">
          <!-- BEGIN COPYRIGHT -->
          <div class="col-md-6 col-sm-6 padding-top-10">
                  &copy; 2025 WAAC | World Academy for Artificial Consciousness<br>
 <a href="javascript:;">Privacy Policy</a> | <a href="javascript:;">Terms of Service</a>
          </div>
          <!-- END COPYRIGHT -->
	  <!-- BEGIN SOCIAL -->
<div class="col-md-6 col-sm-6">
  <ul class="social-footer list-unstyled list-inline pull-right">
    
  </ul>  
</div>
<!-- END SOCIAL -->

        </div>
      </div>
    </div>
    <!-- END FOOTER -->

  <!-- BEGIN CORE PLUGINS (REQUIRED FOR ALL PAGES) -->
<!--[if lt IE 9]>

<script src="/metronic/assets/plugins/respond.min.js"></script>

<![endif]--> 

<script src="/metronic/assets/plugins/jquery.min.js"></script>


<script src="/metronic/assets/plugins/jquery-migrate.min.js"></script>


<script src="/metronic/assets/plugins/bootstrap/js/bootstrap.min.js"></script>


<script src="/metronic/assets/corporate/scripts/back-to-top.js"></script>


<script src="/metronic/assets/plugins/owl.carousel/owl.carousel.min.js"></script>


<script src="/metronic/assets/corporate/scripts/layout.js"></script>


<script src="/js/wow.min.js"></script>



  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<script type="text/javascript">
    jQuery(document).ready(function() {
        Layout.init();    
        Layout.initOWL();
        Layout.initTwitter();
        Layout.initFixHeaderWithPreHeader(); /* Switch On Header Fixing (only if you have pre-header) */
        Layout.initNavScrolling(); 
	new WOW().init();
    });
</script>
<!-- END CORE PLUGINS -->

<!-- BEGIN PAGE-SPECIFIC PLUGINS --> 







<!-- END PAGE-SPECIFIC PLUGINS --> 

<!-- BEGIN INTEGRATIONS -->





<!-- END INTEGRATIONS -->

</body>
</html>
