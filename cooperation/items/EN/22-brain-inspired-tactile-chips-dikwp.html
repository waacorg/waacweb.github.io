<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8 no-js"> <![endif]-->
<!--[if IE 9]> <html lang="en" class="ie9 no-js"> <![endif]-->
<!--[if !IE]><!-->
<html lang="en">
<!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <title>Call for Collaboration：Research on Multimodal Brain Signal Recording and Cognitive Interaction Systems Based on the DIKWP Model and Artificial Consciousness | WAAC | World Academy for Artificial Consciousness</title>

  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="description" content="World Academy for Artificial Consciousness (WAAC)  International Standardization Committee of Networked DIKWP for Artificial Intelligence Evaluation(DIKWP-SC)  World Artificial Consciousness CIC(WAC)">
<meta property="og:type" content="website">
<meta property="og:title" content="Call for Collaboration：Research on Multimodal Brain Signal Recording and Cognitive Interaction Systems Based on the DIKWP Model and Artificial Consciousness">
<meta property="og:url" content="http://www.waac.ac/cooperation/items/EN/22-brain-inspired-tactile-chips-dikwp.html">
<meta property="og:site_name" content="WAAC | World Academy for Artificial Consciousness">
<meta property="og:description" content="World Academy for Artificial Consciousness (WAAC)  International Standardization Committee of Networked DIKWP for Artificial Intelligence Evaluation(DIKWP-SC)  World Artificial Consciousness CIC(WAC)">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-06-28T06:00:00.000Z">
<meta property="article:modified_time" content="2025-07-02T10:47:45.380Z">
<meta property="article:author" content="WAAC Editorial">
<meta property="article:tag" content="artificial consciousness, artificial intelligence, academy">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="WAAC | World Academy for Artificial Consciousness" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico">
  
    
  <meta content="{{ title }}" name="description">
  <meta content="{{ title }}" name="keywords">
  <meta content="{{ title }}" name="author">

  <link href="http://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700|PT+Sans+Narrow|Source+Sans+Pro:200,300,400,600,700,900&amp;subset=all" rel="stylesheet" type="text/css">

  <!-- Global styles START -->   
  
<link rel="stylesheet" href="/metronic/assets/plugins/font-awesome/css/font-awesome.min.css">

  
<link rel="stylesheet" href="/metronic/assets/plugins/bootstrap/css/bootstrap.min.css">

  <!-- Global styles END --> 
   
  <!-- Page level plugin styles START -->
  
<link rel="stylesheet" href="/metronic/assets/pages/css/animate.css">

  
<link rel="stylesheet" href="/metronic/assets/plugins/owl.carousel/assets/owl.carousel.css">

  <!-- Page level plugin styles END -->

  <!-- Theme styles START -->
  
<link rel="stylesheet" href="/metronic/assets/pages/css/components.css">

  
<link rel="stylesheet" href="/metronic/assets/pages/css/slider.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/style.css">

  
<link rel="stylesheet" href="/metronic/assets/pages/css/portfolio.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/style-responsive.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/themes/red.css">

  
<link rel="stylesheet" href="/css/theme-styles.css">

  <!-- Theme styles END -->
<meta name="generator" content="Hexo 7.3.0"></head>

<body class="corporate">
  
<!-- BEGIN HEADER -->
<div class="header">
  <div class="container">
    <!--<a class="site-logo" href="/" id="logo">WAAC | World Academy for Artificial Consciousness</a>-->

    <a class="site-logo" href="/">
    <img src="/images/waac_logo.png" style="width: 80%; max-width: 300px; display: block; margin: 0px;" alt="WAAC logo" />
    </a>

    <a href="javascript:void(0);" class="mobi-toggler"><i class="fa fa-bars"></i></a>

    <!-- BEGIN NAVIGATION -->
    <div class="header-navigation pull-right font-transform-inherit">
      <ul>
	
	<li class="">
	  <a  href="/">Home</a>
	</li>
	
	<li class="">
	  <a  href="/events/">Events</a>
	</li>
	
	<li class="">
	  <a  href="/archives/">News</a>
	</li>
	
	<li class="">
	  <a  href="/Academician/">Academicians</a>
	</li>
	
	<li class="">
	  <a  href="/cooperation/">Collaboration</a>
	</li>
	
	<li class="">
	  <a  href="/Charter/">Charter</a>
	</li>
	
	<li class="">
	  <a  href="/about/">About</a>
	</li>
	
	<!-- BEGIN TOP SEARCH -->
	<li class="menu-search">
	  <span class="sep"></span>
	  <i class="fa fa-search search-btn"></i>
	  <div class="search-box">
	    <form action="#">
	      <div class="input-group">
		<input type="text" placeholder="Search" class="form-control st-default-search-input">
		<span class="input-group-btn">
		  <button class="btn btn-primary" type="submit">Search</button>
		</span>
	      </div>
	    </form>
	  </div> 
	</li>
	<!-- END TOP SEARCH -->
      </ul>
    </div>
    <!-- END NAVIGATION -->
  </div>
</div>
<!-- Header END -->

  <div class="container">
  <ul class="breadcrumb">
    <li><a href="/">Home</a></li>
    <li class="active">Call for Collaboration：Research on Multimodal Brain Signal Recording and Cognitive Interaction Systems Based on the DIKWP Model and Artificial Consciousness</li>
  </ul>
  <div class="main">
    <h1>Call for Collaboration：Research on Multimodal Brain Signal Recording and Cognitive Interaction Systems Based on the DIKWP Model and Artificial Consciousness</h1>
    <ul>
<li><p>World Academy for Artificial Consciousness (WAAC)</p>
</li>
<li><p>International Standardization Committee of Networked DIKWP for Artificial Intelligence Evaluation(DIKWP-SC)</p>
</li>
<li><p>World Artificial Consciousness CIC(WAC)</p>
</li>
<li><p>World Conference on Artificial Consciousness(WCAC)</p>
</li>
<li><p>Email: <a href="mailto:&#100;&#x75;&#97;&#110;&#121;&#x75;&#x63;&#111;&#110;&#103;&#x40;&#104;&#x6f;&#116;&#109;&#97;&#x69;&#108;&#46;&#x63;&#111;&#x6d;">duanyucong@hotmail.com</a></p>
</li>
</ul>
<hr>
<h1 id="Directory"><a href="#Directory" class="headerlink" title="Directory"></a><strong>Directory</strong></h1><p><a href="#_Toc200373555">Background and significance </a></p>
<p><a href="#_Toc200373556">Research Objectives: </a></p>
<p><a href="#_Toc200373557">Research content and technical route </a></p>
<p><a href="#_Toc200373558">Feasibility analysis </a></p>
<p><a href="#_Toc200373559">Phased achievements and assessment indicators </a></p>
<p><a href="#_Toc200373560">Application demonstration and promotion path </a></p>
<hr>
<div style="text-align: justify !important;">

<h1 id="Background-and-significance"><a href="#Background-and-significance" class="headerlink" title="Background and significance"></a><strong>Background and significance</strong></h1><p>Nowadays, brain science and artificial intelligence technology are accelerating the cross-integration, and brain signal recording and decoding have become the frontier hotspots in the field of cognitive computing and human-computer interaction. On the one hand, the brain-computer interface (BCI), as a bridge between the human brain and external devices, shows great potential to expand human intelligence and rehabilitate neural functions. Internationally, scientific research teams and enterprises represented by Neuralink and others are investing heavily in high-throughput brain signal acquisition and decoding technology, and the global brain-computer interface market has exceeded 2 billion US dollars, with a compound annual growth rate of about 17.5%, and the total market size is expected to exceed 6 billion US dollars around 2030. On the other hand, China has listed brain science and brain-like research as a major project of scientific and technological innovation 2030, focusing on the principles of brain cognition, intervention of major brain diseases, brain-inspired computing and brain-computer intelligence technology. &quot;Research on brain signal recording technology&quot; is a key topic in this national strategic deployment, which is related to China&#39;s independent innovation and competitive advantage in the field of new generation artificial intelligence and biomedical engineering.</p>
<p>However, there are still many challenges in the acquisition and decoding of brain signals: <strong>(1) signal acquisition bottleneck</strong>: non-invasive EEG signals are susceptible to noise interference and have limited spatial resolution; Invasive electrodes have high signal quality, but they have safety risks and ethical limitations. <strong>(2) Decoding the semantic gap</strong>: Traditional brain-computer interfaces mostly use data-driven pattern recognition methods, which directly map EEG waveforms to simple instructions, which lack the understanding of the deep connection between signals and cognitive semantics, and it is difficult to accurately reflect the user&#39;s true purpose and perceptual state. <strong>(3) Sustainable system interaction</strong>: Most of the existing brain-computer systems are mainly based on one-way information transmission, which lacks feedback regulation and long-term adaptation mechanism for brain state, which is difficult to meet the needs of human-computer interaction in complex environments. In order to solve the above problems, the introduction of artificial consciousness model and new brain signal acquisition technology as a breakthrough will provide a new idea and technical path for brain signal cognitive decoding.</p>
<p>This project proposes a &quot;DIKWP×DIKWP&quot; mesh interaction model as the core theoretical framework, aiming to integrate the theory of artificial consciousness into the process of brain signal decoding and interaction. <strong>DIKWP is a five-level artificial consciousness model first proposed by Professor Yucong Duan&#39;s team, which includes five levels of &quot;data-information-knowledge-wisdom-purpose&quot;. Compared with the traditional DIKW (pyramid) model, DIKWP adds &quot;Purpose&#x2F;Purpose&quot; at the top layer, and realizes two-way feedback and iterative update of the semantics of each layer through a mesh structure. This innovative cognitive system is an academic milestone, enabling AI to embed human purposes, and providing a new way to solve the &quot;black box&quot; problem of intelligent systems and improve the interpretability of decision-making. In particular, the team further constructed the &quot;dual circulation&quot; DIKWP ×DIKWP architecture, introducing two closed loops: basic cognitive process and metacognitive cycle, to achieve self-monitoring, self-reflection and self-regulation. This &quot;dual circulation&quot; artificial consciousness architecture is seen as an important way to move towards autonomous self-aware AI. For brain signal decoding, the full-link semantic representation and purpose driving mechanism provided by the DIKWP model has unique theoretical value: it lays a foundation for the construction of a common semantic space between brain signals and cognitive semantics, so that brain signal decoding no longer stops at pattern classification, but rises to the</strong> <strong>semantic mapping of self-purpose and perceptual state. The</strong> step-by-step semantic parsing from raw neural data to high-level purpose is supported by a clear hierarchy under the DIKWP framework, which is expected to make the brain signal decoding process more transparent, interpretable, and closer to the user&#39;s subjective purpose.</p>
<p>The introduction of the artificial consciousness model will also establish innovative semantic mapping capabilities between brain signals and self-purpose and perceptual states. Traditional brain signal analysis mainly focuses on mapping signals such as EEG to objective stimuli or motor thoughts, while artificial consciousness emphasizes the representation of subjective <strong>purpose and state of consciousness. For example, with the DIKWP model, specific EEG patterns can be correlated to the user&#39;s level of concentration, emotional state, or operational purpose at the moment,</strong> so that the system understands &quot;<strong>what the user wants to do</strong>&quot; rather than just &quot;<strong>what signals the brain is emitting</strong>&quot;. This semantic mapping innovation capability means that the <strong>decoding of brain signals → semantic purposes and the encoding of semantic → brain signals can be incorporated into a unified framework to achieve a new paradigm of two-way communication between brain and machine. It is worth expecting that, with the support of the artificial consciousness model, the brain-computer interface system is expected to have a certain &quot;adaptive understanding&quot; ability, which can dynamically adjust the interpretation of the user&#39;s brain signals and avoid immutable hard mapping. For example, when a user is detected to be fatigued, the system can change the interaction strategy (such as reducing the difficulty of the task or enhancing the stimulus wake-up) through the feedback path, forming a more intelligent human-machine closed loop.</strong></p>
<p><strong>The breakthrough of brain signal recording technology is of great significance to the national strategy and future industry: first, in the field of cognitive computing, high-precision brain signal decoding is regarded as an important way to reveal the working principle of the human brain and promote strong artificial intelligence. By collecting and analyzing a large number of neural signals, we can deeply understand the neural mechanisms of high-level cognitive functions such as memory, attention, and decision-making, and feed back the construction and optimization of brain-like computing models. Secondly, in terms of human-computer interaction, brain-computer interface provides a new interaction paradigm for human beings, enabling the human brain to directly participate in the process of information exchange and control. For example, the use of brain signals to directly control exoskeletons or robots can help paralyzed patients regain their ability to exercise; Manipulating computers and virtual environments through brainwaves can bring a new experience of &quot;mind control&quot; to ordinary users. The emergence of brain-computer interfaces is subverting the traditional human-computer interaction model, and is regarded as the next generation of general interactive interfaces after keyboards and touch screens, which is expected to give birth to huge emerging industries. Thirdly, in the field of neurological rehabilitation, brain signal recording technology has shown cutting-edge value in adjuvant diagnosis and treatment. For example, by continuously recording the brain activity of epilepsy patients, early warning and closed-loop intervention of seizures can be realized. EEG monitoring and electrical stimulation of comatose patients can help assess residual consciousness and promote arousal; The use of BCI technology for motor imaging training in stroke patients can promote the remodeling of damaged neural circuits and improve the rehabilitation effect. These application scenarios all confirm the strategic significance of high-performance brain signal recording and decoding systems</strong>: it not only serves people&#39;s health and well-being, but also serves as a new engine to promote the intelligent society and digital economy.</p>
<p>To sum up, this project will comply with the requirements of the national key special guidelines of &quot;Brain Science and Brain-like Research&quot;, focus on the bottleneck of brain signal recording technology, integrate the advantages of DIKWP network interaction model and artificial consciousness theory, and open up a new route for cognitive decoding and interaction of multimodal brain signals. Through the implementation of this project, it is expected to enrich the cognitive computing basis of brain information decoding theoretically, break through the key devices and algorithms of new brain-computer interfaces in technology, and lead the development of intelligent medical care and human-computer interaction industry in application, which has important scientific significance and social and economic value.</p>
<h1 id="Research-Objectives"><a href="#Research-Objectives" class="headerlink" title="Research Objectives:"></a><strong>Research Objectives:</strong></h1><p>The overall goal of this project is to develop a new generation of multimodal brain signal recording and cognitive interaction system, and to achieve a technological breakthrough in the whole process from efficient brain signal acquisition, semantic decoding to real-time human-computer interaction. Specifically, it will focus on the following five aspects:</p>
<ol>
<li><p><strong>Research and development of high-throughput, low-power, and high-security brain signal acquisition systems: develop brain signal acquisition devices and chips covering non-invasive, deep and interventional application scenarios. The system should greatly improve the number and quality of signal channels under non-invasive conditions, and explore the safe acquisition of deep brain signals and the integration of minimally invasive interventional electrodes. It is expected to establish a highly biocompatible and miniaturized acquisition system to achieve high-channel-count parallel recording and long-term stable monitoring of neural signals</strong>. System power consumption and heat generation need to be tightly controlled to ensure safety when implanted or worn.</p>
</li>
<li><p><strong>Brain signal semantic structure modeling and cognitive decoding pathway based on DIKWP model: Construct a brain signal decoding algorithm framework with DIKWP artificial consciousness model as the core, and open up the mapping pathway from neural data to cognitive semantics. By introducing the</strong> five-level semantic structure of &quot;data-information-knowledge-wisdom-purpose&quot;, the brain signal features are represented and abstracted at multiple levels, and the high-level semantic markers reflecting the user&#39;s purpose or cognitive state are finally extracted. Develop a decoding model that can support multimodal, dynamic, and hierarchical cognitive state tracking, and form a verifiable mathematical model and algorithm in theory to achieve accurate semantic interpretation of complex brain signals. This goal will lay a new foundation for brain signal decoding to leap from pattern recognition to cognitive understanding.</p>
</li>
<li><p><strong>R&amp;D of adaptive adhesive non-invasive EEG acquisition system: For non-invasive applications, a new type of attached EEG electrodes and sensing components have been developed to</strong> significantly improve the acquisition quality and spatial resolution of EEG signals on the scalp surface. Specifically, high-density electrode arrays made of flexible electronic materials can be developed to fit the scalp surface, reduce contact impedance and improve signal stability; Explore dry electrodes, <strong>microneedle electrodes and other technologies that do not require conductive adhesives, so as to obtain cleaner signals while ensuring user comfort; Design adaptive mechanical structures or smart fitting mechanisms to adapt to different head shapes and head movements to reduce motion artifacts. Through wireless transmission and low-power front-end circuit design, this non-invasive EEG system is portable and easy to use. The expected result is to build a set of wearable and integrated EEG acquisition equipment, which can significantly improve the effective signal-to-noise ratio of traditional scalp EEG and increase the spatial sampling density by several times without reducing the convenience of use.</strong></p>
</li>
<li><p><strong>Construction of real-time interaction system of brain cognitive state based on artificial consciousness: The artificial consciousness model is used to realize the real-time perception of the user&#39;s brain cognitive state and the human-computer interaction response. Develop a closed-loop interactive system integrating software and hardware: the front-end acquisition module perceives the user&#39;s brain activity, and extracts the current purpose</strong> or state indicators such as attention and consciousness clarity through the DIKWP cognitive decoding engine; According to the analysis results of the artificial consciousness system, the back-end execution module gives appropriate feedback or control instructions (such as operating external devices, triggering sensory stimuli, adjusting the interface, etc.) in a timely manner, forming a &quot;brain-computer-environment&quot; continuous cycle interaction mode. In particular, the &quot;<strong>knowledge-purpose-feedback&quot; path in the DIKWP model is</strong> introduced, and a logical link from the environmental knowledge base to user purpose recognition and feedback decision-making is established in the system, so that the interactive system has certain adaptive and self-regulating capabilities. For example, for brain-computer training tasks, the system can automatically adjust the training rhythm or give hints (feedback) according to the user&#39;s brain fatigue level (knowledge) and the purpose of the target task, so as to maintain the best interaction effect. This goal will validate a new paradigm of human-computer interaction driven by artificial consciousness and create a more intelligent brain-computer closed-loop system.</p>
</li>
<li><p><strong>Portable multi-modal brain signal acquisition equipment and digital analysis platform realization: Integrate the above technical achievements to develop a set of multi-modal brain signal acquisition and analysis platform</strong>to meet the dual application needs of medical and brain-like computing. In terms of hardware, it realizes portable integrated devices, modularly supports the synchronous acquisition of multiple brain signal modalities (such as EEG, fNIRS, ECoG, etc.), and has the necessary signal processing and storage capabilities. In terms of software, an open digital analysis platform has been developed, with a built-in cognitive decoding engine with DIKWP structure and a multi-modal data fusion tool, which can process the collected data in real time, visualization and intelligent analysis. The platform should be able to be flexibly configured according to different application scenarios: in medical assistance scenarios, it can be connected to the hospital information system to realize patient brain status monitoring and diagnosis and treatment support; In brain-like computing scenarios, it can interface with AI algorithms and brain simulation systems to support the integration of human brain data and artificial intelligence. Through standardized interfaces and secondary development support, promote the demonstration and promotion of the achievements of the platform. On the basis of ensuring safety and reliability, the final delivered system will achieve high channel count, high spatiotemporal resolution, multi-modal compatible brain signal acquisition, as well as intelligent interpretation and interaction at the semantic level, leading China&#39;s brain-computer interface system to a new generation of intelligent and practical stage.</p>
</li>
</ol>
<h1 id="Research-content-and-technical-route"><a href="#Research-content-and-technical-route" class="headerlink" title="Research content and technical route"></a><strong>Research content and technical route</strong></h1><p>Focusing on the above goals, the research content of this project is divided into five directions, and each direction supports and integrates each other to form a complete technical route:</p>
<ol>
<li>Development of new brain signal acquisition materials, structures and devices: This direction focuses on tackling the hardware foundation of high-throughput and long-term stable brain signal acquisition. The study includes:</li>
</ol>
<ul>
<li><p><strong>Flexible adhesive electrode array: Flexible electronic materials (such as graphene, biocompatible conductive polymers, etc.) are used to develop a malleable electrode array to ensure that the electrodes are tightly attached to the surface of brain tissue (scalp or cortex). Through the innovative electrode structure design (such as grid-like electrodes and comb-shaped electrodes), the electrode coverage density is improved to achieve high spatial sampling rate signal recording.</strong></p>
</li>
<li><p><strong>Optical Interfaces and Mixed-Modal Sensing: Exploring the Application of Optical Methods to Brain Signal Acquisition. On the one hand, a non-invasive near-infrared optical sensing module was developed to realize the measurement of cerebral hemodynamic signal (fNIRS), which is complementary to the electrical signal. On the other hand, optically coupled electrodes or fiber optic probes are studied that combine light sensing</strong>&#x2F;stimulation with electrode recording for the detection of deep brain activity. For example, a photohybrid electrode with an integrated microlight source and a photodetector can be designed to sense local neuronal activity under minimally invasive conditions. High-speed optical data links will also be studied to replace some wired transmissions and improve the data bandwidth and anti-electromagnetic interference capabilities of implanted devices.</p>
</li>
<li><p><strong>Microneedle Electrodes and Micro-Invasive Sensors: Microneedle array electrodes with millimeter scale or smaller are developed to achieve micro-invasive brain signal recording. Microneedle electrodes can be used to lightly puncture the epidermis or dura mater to obtain high-quality subcortical nerve signals with minimal trauma. Research includes novel microfabrication techniques for high-density microneedle arrays, electrode material coating optimization (to reduce impedance and inflammation), and adjustable pose insertion mechanisms for microneedles. For specific applications (e.g., epilepsy monitoring, deep brain signal acquisition), design implantable miniature sensor nodes</strong>, such as field-effect transistor (FET) amplifiers or MEMS sensors at the tip of the needle, to achieve in-situ high signal-to-noise ratio signal capture.</p>
</li>
<li><p>**Ultra-high channel number acquisition circuit and system integration: Develop supporting front-end signal conditioning circuits and digital system structures to meet the concurrent acquisition requirements of hundreds to thousands of channels. The research focuses on ultra-low noise and ultra-low power consumption of multi-channel biological signal amplifier arrays and analog-to-digital conversion (**ADC) chips, and strives to reach the input noise level of &lt;5 μV and μW power consumption per channel. Hybrid synchronous sampling and multiplexing technology are used to realize the synchronous acquisition and high-speed transmission of thousand-channel signals. At the same time, it solves engineering problems such as the compatibility of wireless transmission and MRI for large-scale acquisition: the packaging and shielding design of high-bandwidth wireless communication modules (target more than 10 Mbps) and anti-magnetic field interference are studied. Finally, in terms of system integration, the wireless brain-computer interface chip with more than 128 channels and the prototype of the wired acquisition system with more than 1000 channels are realized, providing high-quality data sources for subsequent brain signal decoding.</p>
</li>
</ul>
<p>DIKWP-driven brain signal encoding-decoding path modeling: this direction focuses on the conversion mechanism and theoretical model of brain signals to cognitive semantics. The study includes:</p>
<ul>
<li><p><strong>Multi-layer feature representation of brain signals: According to the DIKWP architecture, the processing of brain signals is divided into five levels: data, information, knowledge, wisdom, and purpose. The underlying data layer extracts the time-frequency characteristics of the original signal (such as power spectrum and coherence). The information layer further captures patterns and structures (e.g., the synchronization patterns of networks in specific brain regions); The knowledge layer combines prior cognitive knowledge to identify the cognitive process or stimulus category corresponding to the signal. The Wisdom layer synthesizes multi-source information to infer higher-level psychological states or decisions; The Purpose layer is ultimately mapped to the user&#39;s Purpose and</strong> Purpose representations. For example, for the EEG signals of imaginary movement, the data layer extracts μ rhythmic inhibition features, the information layer identifies the connections of movement-related brain regions, the knowledge layer judges that this is the Purpose category of &quot;left hand raised&quot;, the Wisdom layer evaluates that the user wants to complete a certain action, and the Purpose layer confirms the user&#39;s purpose (such as picking up an object).</p>
</li>
<li><p><strong>Semantic decoding algorithm for brain signals: Based on the above representations, a machine learning and inference algorithm that can automatically complete the mapping from signals to semantic labels is developed. Taking into account the nonlinearity and dynamics of brain signals, a combination of deep learning and symbolic inference will be employed: for example, a multimodal neural network will be built to extract EEG</strong>, NIRS and other data features, and at the same time, the relationship between brain function anatomy and task semantics is stored by the knowledge graph, and the two are connected through the DIKWP model interface. In the process of decoding, the algorithm not only outputs simple classification results, but also gives corresponding semantic interpretation paths (such as inferring which cognitive state according to which physiological model) to improve the interpretability and reliability of the results. In particular, the real-time dynamic decoding technology will be studied to cope with the time-varying characteristics of brain signals: sliding time windows and sequential models (such as LSTM, Transformer, etc.) will be used to continuously track the change of Purpose to realize the dynamic update and prediction of the user&#39;s cognitive state.</p>
</li>
<li><p><strong>Multimodal and intermodal coupling modeling: A joint decoding model of modal relationships is established for multi-source brain signals (such as EEG+fNIRS, EEG+EMG, etc.) acquired at the same time. Statistical analysis and deep fusion network are used to reveal the intrinsic connection relationship and coupling mechanism between different signals</strong>. For example, to study the correlation patterns between scalp electrical signals and blood oxygen signals when cognitive load changes, or the mapping between cortical local field potentials and surface EEG. Such modal fusion is expected to overcome the uncertainty of a single signal and improve the accuracy and robustness of decoding. Finally, a unified decoding engine is constructed, which can output standardized cognitive semantic markup regardless of the input or combination of modal data. This lays the foundation for the algorithm of multimodal brain-computer interface applications.</p>
</li>
<li><p><strong>Verifiable theoretical model: While the algorithm is developed, the general theoretical framework of cognitive decoding of brain signals is refined. Based on the hierarchical idea of DIKWP, an interpretable mathematical model is proposed, such as using information theory to quantify the information transfer efficiency between layers, and using the graph model to describe</strong> the reasoning path of knowledge and purpose. Small-scale controllable experiments are used to verify the hypothesis of the model, such as designing a cognitive task paradigm to induce specific brain signal changes, and testing the prediction accuracy of the model for signal-cognitive correspondence. This theoretical model will provide principle guidance for semantic decoding of brain signals and provide a basis for improving system performance.</p>
</li>
</ul>
<p><strong>Construction of the whole process interface of brain signal perception-cognition-execution: This direction is oriented to the integration of the brain-computer-environment closed-loop system, realizes the whole process architecture design of brain signals from acquisition, analysis to driving external response, and emphasizes</strong> the integration of the &quot;knowledge-purpose-feedback&quot; mechanism in the artificial consciousness system. The study includes:</p>
<ul>
<li><p><strong>Perception module</strong>: Integrate the hardware achievements of Direction 1 to build a multi-modal brain signal perception unit. Realize the synchronous acquisition and preprocessing of multi-channel EEG, NIRS and other data, design efficient artifact elimination and feature enhancement algorithms, and extract key neural signal patterns in real time. The perception module needs to have an event detection function, which can output a trigger signal when a significant brain state change or specific pattern (such as motor imagination onset, attention loss, etc.) is captured, and provide timing markers for subsequent processing.</p>
</li>
<li><p><strong>Cognitive Decision-making Module</strong>: Artificial Consciousness ACPU <strong>(Artificial Consciousness Processing Unit),</strong> which has a built-in DIKWP cognitive decoding engine and knowledge-purpose inference model developed by Direction 2. The module receives the feature data input of the perception module, and internally performs inference operations according to the DIKWP semantic hierarchy to obtain the user&#39;s cognitive state evaluation (such as concentration&#x2F;distraction, wakefulness&#x2F;tiredness, etc.) and <strong>purpose discrimination</strong> (such as moving the cursor to the left&#x2F;right and expressing &quot;yes&#x2F;no&quot;) at the current moment. The cognitive module has metacognitive monitoring capabilities, which can evaluate the credibility of the decoding result and self-correct - for example, when the decoding result is uncertain, the perception module can be requested to obtain more data or suspend execution, so as to improve the security of system decision-making.</p>
</li>
<li><p><strong>Action &amp; Feedback:</strong> Responsible for translating cognitive decisions into external actions or feedback stimuli for two-way interaction. On the one hand, the <strong>execution submodule</strong> generates control commands for external devices according to the user&#39;s purpose, such as manipulating the robot arm, moving the cursor, selecting text, etc.; On the other hand, the <strong>feedback submodule imposes appropriate stimuli or cues to the user, including visual, based on the user&#39;s current brain state and task needs</strong>&#x2F;Auditory cues, verbal conversations, or direct modulation of brain states (e.g., transcranial electrical&#x2F;magnetic&#x2F;ultrasound stimulation) via brain stimulation interfaces. In particular, in medical rehabilitation applications, the feedback module can be connected to an electromyography device or a rehabilitation robot to perform functional electrical stimulation or assisted movement on the patient. Through the knowledge base and rules (derived from the knowledge layer of the artificial consciousness model), the feedback method will intelligently adapt to the user&#39;s needs, for example, when the user&#39;s attention is detected, the system will give enhanced stimuli to improve arousal.</p>
</li>
<li><p><strong>Closed-loop control strategy and security mechanism: The overall closed-loop control algorithm is designed</strong> to coordinate the working timing and information flow of the three modules of perception, cognition and execution, so that the system can form a real-time response cycle. Focus on solving the stability and delay problems of closed-loop control, optimize the delay of signal processing and decision-making, and control the total delay of perceived action feedback within an acceptable range (such as hundreds of milliseconds) to ensure the immediacy of interaction. In addition, a rigorous security monitoring mechanism is built to prevent adverse consequences caused by wrong decoding, including double verification of the user&#39;s purpose (the system and the user perform a simple confirmation interaction if necessary), setting the threshold conditions for the system to trigger the action, and immediately stopping the stimulation or controlling the action when the user&#39;s physiological state is abnormal, so as to ensure the safety and controllability of the closed-loop system in various situations.</p>
</li>
<li><p><strong>Prototype system integration and verification: Integrate the above modules in a laboratory environment to build a prototype of a closed-loop brain-computer interface system. Typical application scenarios were selected for validation experiments, such as: <em>Scenario A: Exercise rehabilitation of stroke patients</em>: let the patient try to control the exoskeleton through mind, the system decodes its motor purpose in real time and drives the exoskeleton, and at the same time monitors the patient&#39;s consciousness and promotes behavior through sensory stimulus feedback; <em>Scenario B: Ideation and Typing</em> Communication - Let the person with movement disorder choose the character to spell the word through imagination, the system will determine its purpose in real time and output it on the screen, and the voice assistant will give prompts and encouragement whenever the user&#39;s concentration decreases. Through multiple rounds of experiments, the performance indicators of the closed-loop system in terms of accuracy, response speed, user experience, etc., are evaluated, and the control strategies and parameters are continuously improved to form a stable whole-process interactive system.</strong></p>
</li>
</ul>
<p>Co-design of multimodal EEG&#x2F;brain imaging&#x2F;optical coupling system: This direction aims to co-design a variety of brain functional imaging and signal recording methods, give full play to the advantages of multimodal fusion, and improve the depth and accuracy of monitoring brain cognitive state. The study includes:</p>
<ul>
<li><p><strong>EEG-fNIRS dual-modal system</strong>: An integrated EEG+fNIRS synchronous acquisition device is designed to simultaneously monitor neuroelectrical activity and hemodynamics. In terms of hardware, the layout of EEG electrodes and near-infrared light sources&#x2F;detectors is optimized to reduce mutual electromagnetic and optical interference. Synchronous trigger and time calibration module was developed to ensure that the time alignment error of the two signals is in the millisecond range. Algorithmically, the fusion decoding method of EEG and fNIRS signals was studied, the spatial positioning information provided by blood oxygen changes was used to corroborate the source of EEG brain regions, and the high temporal resolution of EEG was used to analyze the immediate effect of fNIRS changes, so as to achieve higher accuracy than single modality cognitive state discrimination. In particular, for children and adolescents, a bimodal system is used to study the characteristics of brain development, and to extract dynamic neural connection patterns and biomarkers at the development stage.</p>
</li>
<li><p><strong>EEG-Imaging-Photostimulation Coupling</strong>: Explore the possibility of combining EEG with novel brain imaging techniques (e.g., functional ultrasound imaging fUS, optogenetic imaging) and photostimulation methods. In animal models, EEG was attempted to synchronize recording with high-resolution functional ultrasound imaging to obtain a fine map of neural activity in the deep brain. A matching signal processing algorithm was developed to integrate the activity information of deep brain regions provided by fUS into EEG decoding, breaking through the limitation that traditional EEG cannot effectively perceive deep signals. In invasive or semi-invasive conditions, introduce optogenetics**&#x2F;photostimulation interfaces**, such as stimulation of specific neuronal populations with optogenetic probes, while recording feedback on the effects of EEG on the whole brain to establish stimulus-response models. This series of studies will broaden the connotation of multimodal systems to cover <strong>multiple dimensions such as electrical-blood oxygen-ultrasound-light stimulation, and provide richer perception and intervention methods for the design of brain-computer interface systems.</strong></p>
</li>
<li><p><strong>Signal Collaborative Acquisition and Calibration Algorithm</strong>: Solve the problem of multi-modal signal coordination at the physical level and data level. Including: the development of a unified multi-modal data acquisition hardware motherboard, which can interface with different types of sensor modules and provide a unified power supply and clock reference; Develop cross-modal artifact suppression and feature alignment algorithms, such as eliminating the common interference of heartbeat and respiration on EEG and NIRS, and using template matching or independent component analysis to separate the unique components of each modality; Establish a calibration standard for multimodal datasets, which is convenient for mapping data collected by different subjects and different devices to the same frame of reference for comparative analysis. Through co-design and algorithm fusion, the multi-modal system can work stably, reliably, and efficiently, and its output data can be seamlessly fed to the DIKWP decoding engine.</p>
</li>
<li><p><strong>Multimodal synergy validation</strong>: Experiments are designed to verify the utility of multimodal fusion in complex cognitive tasks. For example, driving simulation experiments were carried out to record the driver&#39;s EEG, eye movement, heart rate, etc., to evaluate the accuracy of multi-source signal fusion on the driver&#39;s distraction detection. Or in a brain-computer collaborative game, EEG and EMG can be obtained at the same time to verify whether fusion decoding can more accurately identify the player&#39;s purpose. Through these verifications, the design of the multimodal cooperative system is optimized and provides a basis for subsequent applications.</p>
</li>
</ul>
<p><strong>Development of a cognitive-brain-computer interface platform based on DIKWP structure: This direction integrates all the above R&amp;D results to build a cognitive brain-computer interface platform for practical applications</strong>. The study includes:</p>
<ul>
<li><p><strong>Software and hardware system architecture design: Design a complete platform architecture according to the principle of modularity and scalability. In terms of hardware, based on the equipment of direction 1 and direction 4, it includes a brain signal acquisition cap&#x2F;helmet, a signal conditioning and transmission module, a wearable stimulus feedback module, etc., to form a brain-computer interaction terminal. Plus back-end computing devices or embedded processors (e.g., master control units with integrated ACPU). In terms of software, the core BCI operating system or middleware is developed, and various device drivers, data communication interfaces and algorithm libraries are encapsulated to provide unified task management and resource scheduling. The operating system will be embedded with the DIKWP cognitive architecture, which will enable the platform to have semantic processing capabilities supported by artificial awareness models. Through the collaborative design of software and hardware, the real-time, security and fault tolerance of the system as a whole are ensured.</strong></p>
</li>
<li><p><strong>Medical scenario adaptation and verification: Customize the development and testing of the platform for medical assistive devices and neurological rehabilitation applications. For example, the development of subsystems for motor function rehabilitation, including motor imagination training applications, exoskeleton interfaces, rehabilitation assessment tools, etc., to achieve training assistance for stroke or spinal cord injury patients; To develop a communication assistance subsystem for patients with impaired consciousness, including a simple word selection and spelling interface based on EEG and a visual evoked potential</strong> (VEP) awareness detection tool, etc., to help patients with &quot;locked-in syndrome&quot; realize their basic wishes. Conduct preclinical trials with partner hospitals in real-world clinical settings to validate the effectiveness, safety, and stability of the system in improving patient function and communication. Based on feedback from medical experts and patients, the ergonomic design of the hardware and the human-machine interface friendliness of the software are continuously improved to lay a good foundation for future medical device registration.</p>
</li>
<li><p><strong>Adaptation and verification of brain-inspired computing scenarios: Expand the application of the platform for the field of brain science research and brain-inspired intelligence. For example, the platform is used in brain-computer hybrid intelligence experiments: healthy subjects are allowed to wear devices to participate in complex tasks (such as combining the human brain and AI for image recognition) to study the fusion mechanism of human brain signals and AI decision-making; Or connect the platform to a neuromorphic chip</strong> to obtain the human brain response during chip computing in real time, which can be used to debug and improve the brain-inspired computing model. Develop platform interfaces that support the use of brain science researchers, such as providing flexible programming tools and data recording and analysis modules, so that researchers can use this platform to carry out various brain cognitive experiments. Through these adaptations, it is proved that the platform can not only serve specific applications, but also serve as a scientific research tool to accelerate the basic research of brain-computer integration, and prepare for the emergence of brain-brain fusion technology in the future.</p>
</li>
<li><p>Design for safety and regulatory compliance: In the whole process of platform development, strictly follow the ethics of human trials and the relevant regulatory requirements of medical devices. Formulate a sound data security and privacy protection strategy, and use data encryption, anonymization and other technologies to protect the privacy of subjects. For implantation or electrical stimulation, we work with medical experts to set safety parameter thresholds and establish an emergency braking mechanism to ensure that no serious adverse events occur. Prepare the technical documentation and test reports required for product registration, and strive to ensure that the core modules of the platform pass the test of medical device certification standards (such as biocompatibility, electromagnetic compatibility, software security level, etc.). These efforts will clear the way for the project results to be translated into clinical and industrial applications, and ensure the compliance and trustworthiness of the platform&#39;s application.</p>
</li>
</ul>
<p>The above five research directions are interrelated and progressive: <strong>Direction 1 provides high-quality data sources, Direction 2 empowers data with semantic interpretation capabilities, Direction 3 integrates interpretation into closed-loop control, Direction 4 expands the system perception dimension, and Direction 5 integrates to achieve application implementation. Through the implementation of the technology roadmap, this project will form a complete innovation chain from basic devices to system platforms, fully respond to the requirements of the &quot;Brain Signal Recording Technology Research&quot; guideline, and realize the leapfrog development in this field in China.</strong></p>
<h1 id="Feasibility-analysis"><a href="#Feasibility-analysis" class="headerlink" title="Feasibility analysis"></a><strong>Feasibility analysis</strong></h1><p>This project is led by Prof. Yucong Duan, and relies on his team&#39;s deep research foundation in the field of brain cognitive modeling and artificial intelligence, which has the feasibility of successfully completing the research task.</p>
<p><strong>1. Project Leader and Team Advantages: Professor Yucong Duan is an internationally renowned expert in cognitive computing and artificial intelligence, and is currently an academician of the International Academy of Advanced Technology and Engineering, a corresponding member of the National Academy of Artificial Intelligence of the United States, and the chairman of the World Association of Artificial Consciousness. He has long focused on the research of basic theories and cognitive models of artificial intelligence, and the proposed DIKWP artificial consciousness model has had a wide impact in the academic community and is regarded as an important innovative breakthrough in the AI cognitive system. Professor Duan and his team have an interdisciplinary knowledge background, bringing together talents in the fields of artificial intelligence, cognitive science, biomedical engineering, etc., many of whom have PhDs and overseas research experience. Among them, there are not only algorithm experts who are proficient in machine learning and big data analysis, but also engineering talents who are good at EEG signal processing and hardware development. This kind of multidisciplinary team provides a strong guarantee for the smooth implementation of the project.</strong></p>
<p><strong>2. Basis of previous related research: In terms of brain-cognitive modeling, Professor Duan&#39;s team has carried out a series of research work. For example, in the direction of artificial consciousness, the team built a prototype of a semantic operating system based on the DIKWP model, which decomposes the complex AI decision-making process into five monitorable links: data, information, knowledge, wisdom, and purpose, providing a new solution for the interpretability of AI decision-making. These studies have laid a conceptual and technical foundation for applying the DIKWP model to brain signal decoding. The team has also actively explored research related to brain-computer interfaces, and has achieved preliminary results: including experiments using machine learning to identify emotions and cognitive load on EEG signals, successfully realizing real-time monitoring of participants&#39; fatigue; In cooperation with a medical institution, a study on the communication of patients with consciousness disorders based on EEG was carried out, and the feasibility of specific EEG modes in expressing &quot;yes&#x2F;no&quot; ideation was preliminarily verified</strong>. These preliminary research results and experience show that the team has a certain understanding and technical accumulation of brain signal acquisition and decoding, which provides support for the realization of the goals of this project.</p>
<p><strong>3. Technology and condition reserves: The research units on which this project is based have perfect scientific research conditions. The team has built a professional cognitive neural engineering laboratory</strong>, equipped with high-density 64&#x2F;128-lead EEG acquisition system, functional near-infrared imaging equipment, EEG synchronous stimulation equipment and other instruments, which can meet the needs of multimodal data acquisition experiments. In addition, there is a supporting electronic design and processing laboratory, which can design and package flexible electrodes and microelectronic circuits. The high-performance computing platform developed by the team in the research unit can be used for large-scale brain signal data storage and deep learning training to accelerate algorithm development. The project team has established cooperation channels with a number of hospitals and rehabilitation centers to obtain clinical trial volunteers and valuable EEG&#x2F;neuroimaging data. In terms of intellectual property, Prof. Duan&#39;s team has a series of related invention patents (a total of 114 authorized patents cover cognitive models, artificial consciousness systems, human-computer interaction and other technologies), many of which can be directly used in this project, such as the design of flexible brain-computer interface electrodes, the architecture of artificial consciousness processing units based on DIKWP, etc. These patented technologies will provide a unique source of technology for project research and development, and help form an independent and controllable core technology chain.</p>
<p>4. Feasibility of the project implementation plan: From the perspective of task decomposition and time schedule, the project is divided into five directions: theory, algorithm, device, system and application, which are promoted synchronously and form an organic connection with each other. For example, there are preliminary samples and process routes of flexible electrodes in the hardware direction, the first model of brain electrodecoding in the algorithm direction, and the simple human-machine loop experiment in the pilot project in the closed-loop system direction. These pre-research works have verified the feasibility of key technologies and greatly reduced the risk of project implementation. The milestones in the project plan are clear and achievable: for example, it is expected to complete the hardware prototype development in the first and second years, complete the decoding algorithm and closed-loop system integration in the third year, carry out application verification and optimization in the fourth year, and finalize and prepare the system for promotion in the fifth year. There are clear assessment indicators at each stage, and the team has the confidence and measures to achieve it on time. In particular, in the R&amp;D process, the project will make full use of the team&#39;s artificial intelligence advantages, with the help of simulation and digital twin technology to simulate and verify some complex systems, and accelerate R&amp;D iteration. In general, whether it is team talents, scientific research foundation, experimental conditions, and technical reserves, this project has superior feasibility conditions to ensure the realization of the expected goals.</p>
<h1 id="Phased-achievements-and-assessment-indicators"><a href="#Phased-achievements-and-assessment-indicators" class="headerlink" title="Phased achievements and assessment indicators"></a><strong>Phased achievements and assessment indicators</strong></h1><p>In order to ensure that the project produces high-quality results on schedule, the phased target results and quantitative assessment indicators are as follows:</p>
<ul>
<li><p><strong>(1) High-channel number brain signal acquisition system</strong>: A new type of high-density EEG acquisition device and&#x2F;or implantable microelectrode system has been developed. The assessment indicators include: the number of electrode channels integrated in the non-invasive EEG acquisition cap ≥ 256 channels (more than 4 times higher than the traditional one), the single-channel signal noise ≤ 5 μV, supports wireless data transmission and has a bandwidth of ≥ 10 Mbps; If the implantable prototype is involved, the number of implanted electrode channels reaches the level of 128~1000 channels, and the linewidth of a single electrode is &lt; 10 microns, so as to realize the recording of single neuron potential. The system needs to pass basic biocompatibility and safety tests, and the output signal quality (signal-to-noise ratio, impedance stability) meets laboratory standards.</p>
</li>
<li><p><strong>(2) Multi-modal brain-computer interface collaborative platform</strong>: build a BCI system platform that integrates at least two or more modalities such as EEG and NIRS. Its hardware includes simultaneous acquisition and stimulation equipment, and software includes a multimodal data fusion and real-time processing framework. Assessment indicators: The accuracy of the dual-modal system is improved by &gt;20% compared with that of single-modality in cognitive task experiments, and the EEG and blood oxygen signals can be recorded at the same time with a time synchronization error of &lt; 10 ms. The system delay (from signal generation to feedback) is controlled within 200 ms to meet the requirements of real-time interaction. The platform provides a standard data interface to support parallel experiments with at least 10 subjects, with a stable running time of ≥ 1 hour without obvious drift.</p>
</li>
<li><p><strong>(3) DIKWP cognitive decoding engine</strong>: A brain signal decoding software engine based on the DIKWP model has been developed, including a trained decoding algorithm library and a semantic analysis module. Assessment indicators: The engine can identify at least 3 typical cognitive purposes (such as motor imagery, &quot;Yes&#x2F;No&quot; thinking, and concentration&#x2F;relaxation state), and the decoding accuracy is ≥80% in experimental scenarios; The output includes semantic labels and brief explanation paths to achieve preliminary interpretability. The engine performance meets the requirements of near real-time (a single decoding operation takes &lt; 100 ms) and can be seamlessly embedded in the brain-computer interface operating system. Later in the project, a beta version of the decoding engine will be released for peer trial evaluation and verification of its versatility in real-world applications.</p>
</li>
<li><p><strong>(4) Artificial consciousness driven feedback module</strong>: A feedback control subsystem with artificial consciousness decision-making ability is developed, including ACPU (artificial consciousness processing unit) and interfaces with peripherals&#x2F;stimuli. Assessment indicators: The module can generate appropriate feedback strategies (such as issuing control instructions or adjusting stimulus parameters) within 100 ms according to the user state output by the DIKWP decoding engine. It has a metacognitive monitoring function, which automatically adjusts the output or requests manual intervention when the decoding confidence level is lower than the threshold to avoid major misjudgments. In closed-loop experiments, it was proved that the module can improve the human-computer interaction effect, such as improving the success rate of BCI tasks or shortening the user&#39;s learning time by &gt;15% in the case of relative no feedback. The hardware control interface of the module is compatible with at least 2 external devices (such as electrical stimulators and robotic arms), and can operate reliably and without safety accidents in brain-computer closed-loop experiments.</p>
</li>
<li><p><strong>(5) Application demonstration system and evaluation</strong>: Based on the above results, two demonstration application systems were constructed for the fields of medical rehabilitation and intelligent control, and their performance was evaluated through third-party testing. Specifically, it includes: (1) medical assistance demonstration: such as stroke rehabilitation brain-computer interface system, which helps patients realize the auxiliary execution of specific limb movement purposes; The mental communication system of patients with locked-in syndrome achieves a brain-controlled input speed of at least 5 words per minute. Assessment indicators: After more than 10 cases of trial of patients, the system effectively achieved the expected function, and the patient&#39;s motor function assessment or communication efficiency was significantly improved compared with the baseline (for example, the muscle strength improvement in the rehabilitation training group was better than that in the control group by more than 20%); No serious adverse events were reported. (2) Demonstration of human-machine intelligent control: For example, the system of remote control drone&#x2F;robot can be used to complete the specified task by the brain and mind control equipment after a short period of training. Assessment indicators: more than 5 experiencers successfully controlled the robot to complete the specified operation, with an average accuracy rate of ≥ 90%, and the subjective evaluation system responded naturally and had a good interactive experience. Through these demonstration verifications, the project results will be tested in the actual combat environment, and its technical indicators meet the requirements of the guidelines and reach the international advanced level.</p>
</li>
</ul>
<p>The above-mentioned phased results will be submitted in detail according to the milestone nodes and the results of the physical &#x2F; software, which will be evaluated by the expert group according to the assessment indicators. All key technical indicators must meet or partially exceed the requirements of the national key R&amp;D program guidelines to ensure the high-quality realization of the overall project objectives.</p>
<h1 id="Application-demonstration-and-promotion-path"><a href="#Application-demonstration-and-promotion-path" class="headerlink" title="Application demonstration and promotion path"></a><strong>Application demonstration and promotion path</strong></h1><p>The results of this project have a wide range of application prospects and promotion value, and it is planned to benefit the society through carefully planned demonstration applications and industrial transformation paths.</p>
<p>1. Demonstration of application in the medical field: The results of the project will first be demonstrated in the diagnosis and treatment of brain diseases and neurological rehabilitation. It is planned to cooperate with large tertiary hospitals and rehabilitation centers to select the following typical application scenarios for verification:</p>
<ul>
<li><p><em>Diagnosis and treatment of brain diseases</em>: For brain dysfunction diseases such as epilepsy, depression, autism, etc., the multimodal brain signal acquisition and analysis platform developed by this project is used to carry out auxiliary diagnosis and efficacy monitoring. For example, high-density EEG acquisition and DIKWP decoding algorithms are applied in epilepsy patients to realize automatic detection, prediction and early warning of seizures. In patients with depression, EEG and near-infrared signals are used to monitor their mood-related brain activity, which provides an objective basis for evaluating the effect of drug treatment. These demonstrations will verify the value of the system in clinical monitoring and decision support, and improve the accuracy of disease diagnosis and treatment.</p>
</li>
<li><p><em>Neurological rehabilitation and assistive devices</em>: In the rehabilitation of stroke hemiplegic patients, a brain-controlled exoskeleton training system is deployed, and patients wear brain-computer interface equipment developed by the project to drive the exoskeleton to complete the corresponding actions by imagining limb movements, so as to carry out rehabilitation training. The system evaluates the patient&#39;s motor purpose and concentration in real time, gives appropriate sensory feedback, enhances brain plasticity and promotes recovery. At the same time, brain-computer interface wheelchairs were tried in patients with spinal cord injury, so that high paraplegics could control the movement of wheelchairs with their minds and improve their self-care ability. The demonstration application of these assistive devices will provide a new means of rehabilitation for people with disabilities and greatly improve their quality of life.</p>
</li>
</ul>
<p>In order to promote the implementation of medical demonstration, the project team will assist the partner hospitals to carry out the necessary ethical review and clinical trial filing. User and clinical feedback was collected during the demonstration process to further optimize the system&#39;s human-machine interface and algorithm performance, and improve the user guide and training materials. Through the successful demonstration in the medical industry, the medical credibility of productization is established, and authoritative case support is provided for subsequent promotion.</p>
<p><strong>2. Demonstration of brain-like intelligence and human-computer interaction: The results of the project will also be promoted in a wider range of human-computer intelligent interaction fields. We plan to build an interactive laboratory</strong> for the integration of brain and intelligence, and demonstrate the following applications to scientific research and the public:</p>
<ul>
<li><p><em>Brain-like cognitive interface</em>: connect the platform of this project to the smart home or office environment to create a demonstration <strong>space for &quot;idea control</strong>&quot;. Users can wear brain-computer interface devices to perform operations such as using their brains to control smart speakers to play music, and adjusting the brightness of indoor lighting with their attention levels. This kind of scene display allows the public to intuitively feel the convenience and magic of brain-computer interaction, and promotes its application in the field of Wisdom life.</p>
</li>
<li><p><em>Immersive Entertainment &amp; Education</em>: Partnering with game development companies to develop VR games or training applications based on brain signals. For example, in a brain-controlled VR game, the player drives the action of the game character through meditation or concentration, and the DIKWP decoding engine judges the player&#39;s emotions and purpose in real time to adjust the difficulty of the game to improve the immersion and interactive experience. Another example is the development of attention training software, which uses brain feedback to guide teenagers to enhance their concentration. These applications will validate the attractiveness of the project&#39;s technology in the entertainment and education markets and nurture demand.</p>
</li>
<li><p><em>Industrial &amp; Special Industries</em>: Explore the application of brain-computer interfaces in specific industries, such as the use of brain signals for rapid input to improve operational efficiency in the field of communications, and the use of brain-computer interfaces to improve control accuracy and speed of operation by pilots&#x2F;operators in the aerospace or military fields. This kind of high-end demonstration can help to win the interest and investment of relevant departments and enterprises, and realize the forward-looking layout of technology in key areas.</p>
</li>
</ul>
<p>3. Promotion and industrial transformation path: In order to achieve the long-term sustainable development of the project results, we have formulated a clear promotion and commercialization roadmap:</p>
<ul>
<li><p><em>Patents and standards</em>: Apply for domestic and foreign patents for the core technologies developed by the project in a timely manner, and consolidate independent intellectual property rights. At present, Professor Duan&#39;s team has built a complete patent pool related to DIKWP, and the new achievements of this project will also be included in the scope of patent protection. At the same time, it actively participates in the formulation of domestic brain-computer interface technical standards and ethical norms, and incorporates the methods and indicators accumulated by the project into industry standards to enhance the right to speak and influence.</p>
</li>
<li><p><em>Productization and company incubation</em>: In the later stage of the project, select achievements with high technical maturity and clear market demand to carry out productization work. It is planned to set up a special high-tech start-up company or cooperate with existing industrial partners to promote the engineering and production of brain-computer interface acquisition equipment, <strong>cognitive decoding software suites</strong>, <strong>brain-controlled rehabilitation systems and other products. Leverage the team&#39;s industry connections in the field of artificial intelligence to seek venture capital and industry funding support to accelerate product launch. It is expected that the results of the project will have industrialization potential in the markets of medical rehabilitation equipment, smart wearables, education and entertainment software, etc., and can form a new economic growth point.</strong></p>
</li>
<li><p><em>Training and ecological construction</em>: Through the implementation of this project, a group of interdisciplinary talents who master the cross-technology of brain-computer interface and artificial intelligence will be cultivated, including postdoctoral fellows, doctoral students and young engineers. These talents will become the backbone of related fields in China. The project team will also hold seminars, developer competitions and other activities, establish a brain-computer interface developer community, open up some non-sensitive data and interfaces, and encourage social innovation forces to carry out secondary development based on our platform and jointly enrich the application ecology.</p>
</li>
<li><p><em>Government and public publicity</em>: Strengthen communication with government authorities, report on the results of the project phase, and strive to be included in a wider range of science and technology plans or application demonstration projects. At the same time, the significance of brain-computer interface and artificial consciousness is publicized to the public through mainstream media and popular science activities, so as to eliminate the public&#39;s doubts about new technologies and create a good atmosphere of social acceptance. Especially for medical users and people with special disabilities, we pay attention to publicizing actual cases and effects, and enhance their confidence and expectations in this technology.</p>
</li>
</ul>
<p>Through the above multi-level and multi-channel promotion paths, the research results of this project will not only stay in the laboratory prototype stage, but also be able to move towards practical application and gradually form industrialization capabilities. Looking forward to the future, the brain-computer interaction technology based on the DIKWP model and artificial consciousness is expected to become a landmark achievement in the field of integration of brain science and intelligent technology in China, and help seize the commanding heights of international innovation. We believe that with the support of the National Key R&amp;D Program, this project will achieve the expected goals and make a pioneering contribution to the understanding of the brain and the transformation of human life.</p>
</div> 
  </div>
</div>

    <!-- BEGIN PRE-FOOTER -->
    <div class="pre-footer">
      <div class="container">
        <div class="row">
          <!-- BEGIN BOTTOM ABOUT BLOCK -->
          <div class="col-md-4 col-sm-6 pre-footer-col">
            <h2>About Us</h2>
            <p>World Academy for Artificial Consciousness(WAAC)</p>
          </div>
          <!-- END BOTTOM ABOUT BLOCK -->

          <!-- BEGIN BOTTOM CONTACTS -->
          <div class="col-md-4 col-sm-6 pre-footer-col">
            <h2>Contact</h2>
            <address class="margin-bottom-40">
              Paris, France<br>
              <!-- <br>
              <br> -->
              <!-- Phone: <br> -->
              Email: <a href="mailto: contact@waac.ac"> contact@waac.ac</a><br>
            </address>
          </div> 
          <!-- END BOTTOM CONTACTS -->

	
          <!-- BEGIN TWITTER BLOCK --> 
          <div class="col-md-4 col-sm-6 pre-footer-col">

	  <!-- <a data-tweet-limit="1" class="twitter-timeline" data-theme="dark"
	  target="_blank" rel="noopener" href="https://twitter.com/computerlab_">Tweets by @computerlab_</a> -->

	  <script>!function(d,s,id){var
	  js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

          </div>
          <!-- END TWITTER BLOCK -->
	
        </div>
      </div>
    </div>
    <!-- END PRE-FOOTER -->

    <!-- BEGIN FOOTER -->
    <div class="footer">
      <div class="container">
        <div class="row">
          <!-- BEGIN COPYRIGHT -->
          <div class="col-md-6 col-sm-6 padding-top-10">
                  &copy; 2025 WAAC | World Academy for Artificial Consciousness<br>
 <a href="javascript:;">Privacy Policy</a> | <a href="javascript:;">Terms of Service</a>
          </div>
          <!-- END COPYRIGHT -->
	  <!-- BEGIN SOCIAL -->
<div class="col-md-6 col-sm-6">
  <ul class="social-footer list-unstyled list-inline pull-right">
    
  </ul>  
</div>
<!-- END SOCIAL -->

        </div>
      </div>
    </div>
    <!-- END FOOTER -->

  <!-- BEGIN CORE PLUGINS (REQUIRED FOR ALL PAGES) -->
<!--[if lt IE 9]>

<script src="/metronic/assets/plugins/respond.min.js"></script>

<![endif]--> 

<script src="/metronic/assets/plugins/jquery.min.js"></script>


<script src="/metronic/assets/plugins/jquery-migrate.min.js"></script>


<script src="/metronic/assets/plugins/bootstrap/js/bootstrap.min.js"></script>


<script src="/metronic/assets/corporate/scripts/back-to-top.js"></script>


<script src="/metronic/assets/plugins/owl.carousel/owl.carousel.min.js"></script>


<script src="/metronic/assets/corporate/scripts/layout.js"></script>


<script src="/js/wow.min.js"></script>



  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<script type="text/javascript">
    jQuery(document).ready(function() {
        Layout.init();    
        Layout.initOWL();
        Layout.initTwitter();
        Layout.initFixHeaderWithPreHeader(); /* Switch On Header Fixing (only if you have pre-header) */
        Layout.initNavScrolling(); 
	new WOW().init();
    });
</script>
<!-- END CORE PLUGINS -->

<!-- BEGIN PAGE-SPECIFIC PLUGINS --> 







<!-- END PAGE-SPECIFIC PLUGINS --> 

<!-- BEGIN INTEGRATIONS -->





<!-- END INTEGRATIONS -->

</body>
</html>
